基于标签的推荐

[传送门][0]

[toc]
#####一、简述与原理
最近看一些推荐系统的东西。比较感兴趣的是基于标签的推荐系统。也就是通过用户的标签行为建立起用户和目标物品的联系，从而挖掘用户的兴趣或者是尽兴定向的推荐。

一个用户的标签行为一般由一个三元组组成<用户，物品，标签>(<u,i,b>)即用户u给物品i打上了b标签。

一个简单的基于标签的推荐系统可以通过如下步骤实现：
1. 统计每个用户最常用的标签
2. 对于每个标签，统计被打过这个标签次数最多的物品
3. 对于一个用户，找到它常用的标签， 从而找到具有这些标签的热门物品进行推荐。

假设用 records表示存储标签数据的三元组，即： records[i] = [user,item,tag]

* user_tags 存储用户u打过标签b的次数，即 user_tags[u][b] = n;
* tag_items 存储物品i被打过标签b的次数，即 tag_item[b][i] = n;
* user_items 存储用户所打过标签的物品， 即 user_items[u][i] = n;

#####二、实例程序
```python
#!/usr/bin/env python
#-*-encoding:utf-8-*-

import random

#注： 这里的输入数据的一条记录是一个三元组 ：  (user,item,tag)
#实际上一条交易记录被拆分成了多条这样的记录。
#统计各类数量
def addValueToMat(theMat,key,value,incr):
	if key not in theMat:   # 如果key没有现在theMat中
    	theMat[key] = dict()
        theMat[key][value] = incr;
    else:
    	if value not in theMat[key]:
        	theMat[key][value] = incr;
        else:
        	theMat[key][value] += incr;    # 若有值，则递增
            
def addKeyToDict(theDict,key,incr):

	# theDict[key]=(theDict[key] + incr) if key in theDict.keySet() else incr
 	if key not in theDict.keySet():
    	theDict[key] = incr
    else:
    	theDict[key] = theDict[key] + incr
        
            
user_tags = dict()          #用户到标签的计数
tag_items = dict()          #标签到物品的计数
user_items = dict()         #用户到物品的计数
user_items_test = dict()    #测试数据集
item_stat = dict()          #不同的item的计数
tags_stat = dict()          #不同的tag的计数



#初始化 ，进行各种统计
def InitStat(infile):
	data_file = open(infile,'r')
    line = data_file.readline();
    
    while line:
    	if random.random()>0.1:    #将 90%的数据作为训练集，剩下的10%测试集
        	terms = line.split("\t")    # 训练集的数据结构是[user,item,tag]
            user = terms[0]
            item = terms[1]
            tag  = terms[2]
            #将数据添加到 统计矩阵中
            addKeyToDict(item_stat,item,1)    # 统计各个item访问的用户数
            addKeyToDict(tags_stat,tag,1)     # 统计各个tag访问的用户数
            
            addValueToMat(user_tags,user,tag,1)
            addValueToMat(tag_items,tag,item,1)
            addValueToMat(user_items,user,item,1)
            line = data_file.readline()
            
        else:
        	addValueToMat(user_items_test,user,item,1) #填充测试数据集
        
    data_file.close()
    
#推荐算法
#初始版   u_list * item_list   
# user_list = (tag_1_u_w,tag_2_u_w,...,tag_n_u_w)
# item_list = (tag_1_i_w,tag_2_i_w,...,tag_n_i_w)

def Recommand(user):
	recommand_list = dict()
    tagged_item = user_items[usr]  #得到该用户所有推荐过的物品
    for tag_,wut, in user_tags[usr].items(): # 用户打过的标签以及次数
    	for item_,wit in tag_items[tag_].items(): #物品被打过的标签以及次数
        	if item_ not in tagged_item: # 已经推荐过的不再推荐
            	recommend_list[item_] = wut * wit # 计算公式
            else:
            	recommend_list[item_] += wut * wit
    return recommend_list
    
#TF-idf改进版 
#p(u,t) = $\sum_b \frac{n(u,b)}{log(1 + n(b))} * frac{n(b,i)}{1 + n(i)}$
#这里的n(*) 都是对括号内元素的 用户动作的统计
# 这里可以看作两个文档集  set（u -> list(tag)） 和 set(item -> list(tag))
# 文档中的频数是  该标签 的购买次数
# 这两文档集都使用tag作为特征词， 所要作的就是寻找分属于两个文档集的文档的 相似度
# 所以计算user 和 item 关于特征 tag 的空间向量 
def TFIDFRecommend(user):
	recommand_list = dict()
    tagged_item = user_items[usr]  #得到用户已经购买过的物品
    for item in item_stat.keyset():
    	recommand_list[item] = 0.0
    for item in item_stat.keyset():
    	for tag in tag_stat.keyset():
        	n_u_t = user_tags[user][tag]
            n_t_i = tag_items[tag][item]
            n_t   = tag_stat[tag]
            n_i   = item_stat[item]
            #这里idf的值进行计算的时候不除以总文档数，使用为 item 和 tag的用户相同
            p_t = n_u_t / log(1 + n_t)
            p_i = n_t_i / log(1 + n_i)
            recommand_list[item] += p_t * p_i
    return recommand
            
            
            

#验证 推荐的命中率   
def main(filename，recommend_len):
	#这里进行测试  完成了统计矩阵的 初始化
    InitStat(filename)
    
    #进行测试 
    post_num=0   #看用户购买的物品是否在 推荐列表中
    for (user_,item_) in user_items_test.items:
    	re_list = Recommand(user_)
        #sort_list = sorted(re_list.items,lambda (key,value): value )    #对推荐列表进行排序
        sort_list = sorted(re_list.items,cmp= lambda x,y: cmp(x[1],y[1]),reverse=True )
        rec_items = [item[0] for item in sort_list ]
        post_num = (post_num+1) if item_ in rec_items[:recommend_len] else post_num
    
    accurate_per = post_num / float(len(user_items_test))
    
    print "推荐命中率为 ： %d%%" % ((accurate_per * 10000) / 100) 
    
       
if __name__ == "__main__":
	
    filename = sys.argvs[0]
    recommend_len = sys.argvs[1]
    
    mian(filename,recommend_len)
         
```

#####三、使用TF-IDF算法对推荐精度进行提升

######问题描述：
使用用户打标签次数*物品打标签次数做乘积的算法虽然简单，但是会造成热门物品推荐的情况。物品标签的权重是物品打过该标签的次数，用户标签的权重是用户使用过该标签的次数，从而导致个性化的推荐降低，而造成热门推荐。

######改进策略
运用TF-IDF的思想可以对算法进行改进。TF-IDF（term frequemcy-inverse documnet frequency）是一种用于资讯检索和文本挖掘的加权技术。用来评估一个词的重要程度。其主要思想是如果某个词或短语在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。IDF是逆向文件频率，即包含某个term的文件越少，则IDF越大。

IDF可以由总文件数目除以包含该词语的文件的数目，然后取对数得到：
![][1]

其中D代表文件的总数，分母代表包含该词语的文件的数目，为避免分母为0，通常用1+分母作为当前的分母。这样，当包含该词语的文件在总文件数量中所占比重很小时，能够得到较大的TDF，从而能够得到较大的比重，有利于实现个性化的推荐。（但是引入的TDF却单纯的突出了小频率词汇的权重，从而又可能会给结果带来不好的影响）
则TF-TDF = TF * TDF就反映了一个词对于整个文档集的重要程度。

将TF-IDF应用到基于标签的推荐系统的算法中，则可以进行如下改进：

![][2]

其中n(b)表示标签b被多少不同的用户所使用过。

同理，用n(i)表示物品i被多少个不同的用户打过标签，可以减少热门物品的权重，从而有效的避免热门物品的影响。

![][3]


#####四、继续改进 提高新颖性 
   因为 用户 和  物品的标签向量可能非常稀疏 ，导致过热的问题。
   可以使用word2ec 计算标签的空间向量,然后再对其进行fuzzy聚类。
   对于物品可以使用 word2vec 对其进行fuzzy聚类（每个类成员按照一定的比例属于该类），也可以使用常规的文本空间向量生成方法，产生文本向量，在上面的算法中使用泛化类来泛化数据 ，即item类包含了item类中物品的交易统计量，tag类包含了 tag类中tag的统计信息，用相似度来分推荐权重。
 
1. 每个成员为泛化类贡献 统计量的规则
  如果$item_1$以概率$p_1$属于  类 $item-cls_1$  与用户 $user_1$ 以概率 $p_2$ 属于类 $user-cls_1$
 * 记 item_1 的 tag （tf-idf）权值向量为 ：
  $$(wi_1,wi_2,...,wi_n)$$
 * 记 user_1 的tag 权值向量为：
  $$(wu_1,wu_2,...,wu_n)$$ 
  
 * 那么 item_1 贡献给 item_cls_1 的权重向量为：
  $$(wi_1,wi_2,...,wi_n) * p_1$$
 * user_1 贡献给 user_cls_1的权重向量为：
  $$(wu_1,wu_2,...,wu_n) * p_2$$
  
 * 各个类的中心向量为 各个成员权重向量以各自属于该类的概率的加权平均值向量 
  $$\sum_{t \in c_i} (wi_1,wi_2,...,wi_n) * p_t / \sum p_t$$
  $$\sum_{t \in c_u} (wu_1,wu_2,...,wu_n) * p_t / \sum p_t$$
   
2. 最后关联权重的计算
  如果item_1以概率p1属于  类 item_cls_1  与用户 user_1 以概率 p_2 属于类 user_cls_1 ,两个类的权重是 ：w_u_i
   那么 user_1 和 item_1 之间的关联权重是  :
   $$ p_{ui}=\sum_{i \in c_u,j \in c_i}p_i * p_j * wui_{i,j}$$

注：这里的成员属于各个泛化类的概率是 进行 fruzzy 聚类时算法给出的。




[0]:http://blog.csdn.net/minedayu/article/details/39429873
[1]:http://upload.wikimedia.org/math/0/2/5/0257ce95c505ab568d7898faa56a4f5c.png
[2]:http://img.blog.csdn.net/20141008232330704?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbWluZWRheXU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast
[3]:http://img.blog.csdn.net/20141008232649106?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbWluZWRheXU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast


