
随机模拟的基本思想和常用采样方法（sampling） 

[toc]

通常，我们会遇到很多问题无法用分析的方法来求得精确解，例如由于式子特别，真的解不出来；

一般遇到这种情况，人们经常会采用一些方法去得到近似解（越逼近精确解越好，当然如果一个近似算法与精确解的接近程度能够通过一个式子来衡量或者有上下界，那么这种近似算法比较好，因为人们可以知道接近程度，换个说法，一般一个近似算法被提出后，人们通常都会去考察或寻求刻划近似程度的式子）。

本文要谈的随机模拟就是一类近似求解的方法，这种方法非常的牛逼哦，它的诞生虽然最早可以追溯到18xx年法国数学家蒲松的投针问题（用模拟的方法来求解\pi的问题），但是真正的大规模应用还是被用来解决二战时候美国佬生产原子弹所碰到的各种难以解决的问题而提出的蒙特卡洛方法（Monte Carlo)，从此一发不可收拾。

本文将分为两个大类来分别叙述，首先我们先谈谈随机模拟的基本思想和基本思路，然后我们考察随机模拟的核心：对一个分布进行抽样。我们将介绍常用的抽样方法，1. 接受-拒绝抽样；2）重要性抽样；3）MCMC（马尔科夫链蒙特卡洛方法）方法，主要介绍MCMC的两个非常著名的采样算法（metropolis-hasting算法和它的特例Gibbs采样算法）。

#####一、随机模拟的基本思想
我们先看一个例子：现在假设我们有一个矩形的区域R（大小已知），在这个区域中有一个不规则的区域M（即不能通过公式直接计算出来），现在要求取M的面积？ 怎么求？近似的方法很多，例如：把这个不规则的区域M划分为很多很多个小的规则区域，用这些规则区域的面积求和来近似M，另外一个近似的方法就是采样的方法，我们抓一把黄豆，把它们均匀地铺在矩形区域，如果我们知道黄豆的总个数S，那么只要我们数数位于不规则区域M中的黄豆个数S1，那么我们就可以求出M的面积：M=S1*R/S。

另外一个例子，在机器学习或统计计算领域，我们常常遇到这样一类问题：即如何求取一个定积分：$\inf _a ^b f(x) dx$， 如归一化因子等。

如何来求解这类问题呢？当然如果定积分可以解析求出，直接求出即可，如果不能解析求出，只能求取近似解了，常用的近似方法是采用蒙特卡洛积分，即把上述式子改写为：
$$\inf _a^b f(x)*g(x)/g(x) dx = \inf _a^b (1/g(x)) *f(x)*g(x) dx$$

那么把f(x)/g(x)作为一个函数，而把g(x)看做是[a,b]上的一个概率分布，抽取n个样本之后，上述式子可以继续写为：
$${\sum _1^n [f(x_i)/g(x_i)]}/n$$

，当n趋向无穷大的时候，根据大数定理，上述式子是和要求的定积分式子是相等的，因此可以用抽样的方法来得到近似解。

通过上述两个例子，我们大概能够理解抽样方法解决问题的基本思想，其基本思路就是要把待解决的问题转化为一种可以通过某种采样方法可以解决的问题，至于怎么转化，还是挺有创造性，没有定法。因此随机模拟方法的核心就是如何对一个概率分布得到样本，即抽样（sampling）。因此下一节，我们将介绍常用的抽样方法。

#####二 、 常见的抽样方法

###### 2.0 直接抽样法
略，因为较为简单，而且只能解决很简单的问题，一般是一维分布的问题。

######2.1 接受-拒绝抽样（Acceptance - Rejection sampleing）
又简称拒绝抽样，直观地理解，为了得到一个分布的样本，我们通过某种机制得到了很多的初步样本，然后其中一部分初步样本会被作为有效的样本（即要抽取的分布的样本），一部分初步样本会被认为是无效样本舍弃掉。这个算法的基本思想是：我们需要对一个分布f(x)进行采样，但是却很难直接进行采样，所以我们想通过另外一个容易采样的分布g(x)的样本，用某种机制去除掉一些样本，从而使得剩下的样本就是来自与所求分布f(x)的样本。
它有几个条件：1）对于任何一个x，有f(x)<=M*g(x); 2) g(x)容易采样；3) g(x)最好在形状上比较接近f(x)。具体的采样过程如下：
1. 对于g(x)进行采样得到一个样本xi, xi ~ g(x);
2. 对于均匀分布采样 ui ~ U(a,b);
3. 如果ui<= f(x)/[M*g(x)], 那么认为xi是有效的样本；否则舍弃该样本； （# 这个步骤充分体现了这个方法的名字：接受-拒绝）
4. 反复重复步骤1～3 ，所需要的样本达到要求位置

该方法如图所示：
![][1]

(说明：这是从其他地方弄来的图，不是自己画的，符号有些和文中不一致，其中$\pi(x)$ 就是文中的f(x)，q(x)就是文中的g(x)  )

他需要满足一些条件：
![][2]

具体的采集过程如下：
![][3]

几何上的解释如下：
![][4]

由上面的解释可知，其实是在给定一个样本x的情况下，然后又随机选取一个y值，该y值是在轮廓线Mq(x)下随机产生的，如果该y值落在2条曲线之间，则被拒绝，否则就会被接受。这很容易理解，关于其理论的各种推导这里就免了，太枯燥了，哈哈。
######2.2重要性采样（Importance Sampling）
重要性采样和蒙特卡洛积分密切相关，看积分：

$$\inf f(x) dx = \inf f(x)*(1/g(x))*g(x) dx$$
如果g(x)是一个概率分布，从g(x)中抽取N个样本，上述的式子就约等于
$$(1/N)* \sum f(xi)*(1/g(xi))$$
这相当于给每个样本赋予了一个权重，g(xi)大意味着概率大，那么N里面含有这样的样本xi就多，即这些样本的权重大，所以称为重要性抽样。

抽样的步骤如下：

1. 选择一个容易抽样的分布g(x),从g（x）中抽取N个样本；
2. 计算 $(1/N)* \sum f(xi)*(1/g(xi))$，从而得到近似解。

我对重要性采样的理解是该方法目的并不是用来产生一个样本的，而是求一个函数的定积分的，只是因为该定积分的求法是通过对另一个叫容易采集分布的随机采用得到的（本人研究比较浅，暂时只能这么理解着）。如下图所示：
![][5]

其中通过对q(x)的随机采样，得到大量的样本x，然后求出f(x)*w(x)的均值，最终得出积分I值。其中的w(x)也就是重要性了，此时如果q(x)概率大，则得到的x样本数就多，这样w(x)的值也就多了，也间接体现了它越重要。

######2.3 MCMC抽样方法
无论是拒绝抽样还是重要性采样，都是属于独立采样，即样本与样本之间是独立无关的，这样的采样效率比较低，如拒绝采样，所抽取的样本中有很大部分是无效的，这样效率就比较低，MCMC方法是关联采样，即下一个样本与这个样本有关系，从而使得采样效率高。MCMC方法的基本思想是：通过构建一个markov chain使得该markov chain的稳定分布是我们所要采样的分布f(x)。如果这个markov chain达到稳定状态，那么来自这个chain的每个样本都是f(x)的样本，从而实现抽样的目的。这里存在一个核心问题，如何构建满足要求的markov chain？（什么是markov chain，什么是稳定分布，请查资料，这里假设读者已知。）
在本文，我们介绍两个著名MCMC抽样方法，它们能够方便地构建满足要求的markov chain。

* Metropolis-Hasting 算法
这个算法是两个作者的合称，但不是同一篇论文的，一个是1953年，另外一个是197x年对1953年的工作进行了一些扩展，所以以这两位作者的名字来命名这个算法。

假设要采样的概率分布是$\pi(x)$，现在假设有一个概率分布p(y|x)，使得$\pi(x)*p(y|x) = \pi(y)*p(x|y)$成立，称细致平衡公式，这个细致平衡公式是markov chain能达到稳定分布的必要条件。因此关键是构建出一个概率分布p(y|x)使得它满足细致平衡。现在假设我们有一个容易采样的分布q(y|x)（称为建议分布)，对于目前的样本x，它能够通过q(y|x)得到下一个建议样本y，这个建议样本y按照一定的概率被接受或者不被接受，称为比率 :

$$\alpha(x, y) = min \{ 1, q(x|y)*\pi(y)/[q(y|x)*\pi(x)] \}$$

即如果知道样本xi，如何知道下一个样本$x_{i+1}$是什么呢？就是通过q(y|xi)得到一个建议样本y，然后根据$\alpha(xi, y)$决定$x_{i+1}=y$ 还是$x_{i+1}=xi$。可以证明分布$q(y|x)*\alpha(x,y)$满足细致平衡，同时可以证明这样抽取得到的样本是分布\pi(x)的样本。具体的步骤如下：

1.  给定一个起始样本$x_0$和一个建议分布q(y|x)；
2.  对于第i个样本xi，通过q(y|xi)得到一个建议样本y；计算比率$\alpha(xi, y)= min\{1, q(xi|y)*\pi(y)/[q(y|xi)*\pi(xi)]\}$;
3.  抽取一个均匀分布样本ui ~ U(0,1)，如果$ui <= \alpha(xi,y)$，则$x_{i+1} = y$；否则$x_{i+1} = xi$；
4.  重复步骤2~3，直到抽取到想要的样本数量为止。

课本上的步骤：

![][6]
如果，建议分布q(y|x) 满足：q(y|x) = q(x|y)，即对称，这个时候比率$\alpha(x, y) = min\{1, \pi(y)/\pi(x)\}$就是1953年最原始的算法，后来hasting把这个算法扩展了，不要求建议分布式对称的，从而得到了上述的算法。然而这个算法有一个缺点，就是抽样的效率不高，有些样本会被舍弃掉。从而产生了Gibbs算法。


* Gibbs采样算法

Gibbs算法，很简单，就是用条件分布的抽样来替代全概率分布的抽样。例如，X={x1,x2,...xn}满足分布p(X)，如何对p(X)进行抽样呢？如果我们知道它的条件分布$p(x1|X_{-1}),...,p(xi|X_{-i}),....，$其中X_{-i}表示除了xi之外X的所有变量。如果这些条件分布都是很容易抽样的，那么我们就可以通过对条件分布的抽样来对全概率分布p(X)进行抽样。

Gibbs采样算法的步骤：
1. 给定一个初始样本X0={x10,x20,...,xn0}
2. 已知一个样本Xi={x1i,x2i,...,xni}，对于$x1_{i+1}$进行抽样，$x1_{i+1} ~ p(x1|Xi_{-1})$
3. 对于$x2_{i+1}$进行抽样，$x2_{i+1} ~ p(x2|x1_{i+1}, x3i,...xni)$
... ...
4. 对于$xn_{i+1}$进行抽样，$xn_{i+1} ~ p(xn|x1_{i+1}, x2_{i+1},...x_{n-1}_{i+1})$
5. 步骤2~4可以得到X的一个样本，然后重复步骤2~4可以不断地得到X的样本。

课本上的算法：
![][7]

当然无论是metropolis-hasting算法还是gibbs算法，都有一个burn in的过程，所谓burn in的过程就是因为这个两个算法本身都是markov chain的算法，要达到稳定状态需要一定的步骤才能达到，所以需要一个burn in过程，只有在达到平衡状态时候得到的样本才能是平衡状态时候的目标分布的样本，因此，在burn in过程中产生的样本都需要被舍弃。如何判断一个过程是否达到了平衡状态还没有一个成熟的方法来解决，目前常见的方法是看是否状态已经平稳（例如画一个图，如果在较长的过程中，变化已经不大，说明很有可能已经平衡）当然这个方法并不能肯定一个状态是否平衡，你可以举出反例，但是却是实际中没有办法的办法。

可以证明Gibbs算法是metropolis-hasting算法的一个特例,即比率 $\alpha(x,y) = 1 $的一个特列。具体证明，此处略。

#####理解模拟退火算法
本文将对模拟退火算法（Simulated Annealing)进行介绍，深入理解这个算法。
模拟退火算法和上一篇文章随机模拟算法中的Metropolis算法有着紧密的联系，在这里将详细探讨这种关系。
我们先从这个算法要解决的问题出发，逐步引出相应的算法。

###### 一、问题
人们经常遇到这样的问题：在某个定义域S内，求某个函数f(x)的最小值，形式化为Min f(x)，x属于S。这是一个优化问题，根据f(x)的形式不同，有很多的优化算法来解决这类问题，简单的有穷举法（适用于定义域小的情况），图解法，数学分析法（求导数法）等精确算法，如果很难精确求得，还有很多的近似求解法，如贪心法（如爬山法，最速下降法，梯度下降法），随机模拟方法（MCMC等）。本文将介绍的模拟退火方法属于随机模拟方法，但是是可以求得精确解的（概率为1求得全局优化解），神奇吧！

######二、算法的基本思想
那怎么求解f(x)的最小值呢？它的思想是利用Gibbs分布：S中的一个点x的概率满足分布：p(x, T) = EXP(-f(x)/T)/Z，Z是归一化因子。现在假设T-> 0，可以看到f(x)越小，p(x,T)越大，意味着f(x)以非常大的概率取得最小值，这就是基本思想。

现在是怎么操作的问题，这个分布是确定的，T已知，f(x)的表达式已知（对一个值，就是可以计算出来量），p(x,T)这个分布的形式就已知了，这时候我们利用Metropolis模拟算法去对这个分布抽样，在样本中，出现最多的非常有可能就是我们要求的最小值。似乎问题都解决了，然而如果直接把T设为很小，这个算法的计算时间太长了，因为S可能太大！不实用！

因此，我们采用了层层推进的办法，我们先把T设为一个较大的值Ti，然后在这个Ti的情况下采样，这个时候由于约束条件的限制，p(x，Ti)的定义域只是S的子集，因此速度较快，在采样分布稳定之后，再通过一个T的控制函数g(Ti, Tj)（是一个单调不增函数，T>=0）得到一个更小的Tj，然后在Tj的情况下，再对分布p(x, Tj)采样，直到达到稳定分布，我们可以知道这个时候f(x)比起Ti时候的f(x)变得更加小了，直到达到较小T的时候（自己设定）我们可以认为达到了优化解的情况。

######模拟退火算法 （simulated annealing）
算法的总结如下

```shell
设定起始值T0，T的控制函数g(Ti,Tj)

while(T还没有达到我们预设的值)
{
   对这时的T情况下的Gibbs分布 p(x,T)用 Metropolis 模拟算法进行采样X（t），直到达到稳定状态为止，然后进入下一个循环。
}
```

循环中对p(x,T)进行Metropolis采样的算法如下，它也是一个循环：
```shell
已知T，当前的样本x(t)（来自上一次循环的最后一个样本）， 建议分布为 h(x(t),x(t+1))

while(未达到稳定状态)
{
	先抽取一个建议样本 y~ h(x(t),x(t+1))
    
    if(f(y) < f(x(t))) {
       令 x(t+1) = y;
    }else{
    	令 a  = min {1, p(x(t+1),T) / p(x(t),T)};
        然后抽取 u ~ Uniform(0,1);
        if ( u < a ){
        	x(t+1) = y;
        }else
        {
        x(t+1) = x(t);
        }
    }
}
```

上面的循环完全就是Metropolis 算法
至于，这个算法的名字：模拟退火，来自于我们这个过程和物理学中打造钢铁时候的加热-等温-降温过程，这里的T为温度，f(x)可以令为能量，上述的Metropolis过程就相当于等温过程，p(x, T)就是在T时候系统所处状态的概率分布，可以明显的看到，这个概率与系统的能量和温度密切相关，大部分的资料都是先将这个物理过程，然后再讲算法本身，如果人们不熟悉这个物理过程，简单的介绍反而会使得大家对这个算法搞不清楚。因此，本文为了叙述清楚，没有描述这个过程，反而更加的清楚！

###### python 实现
模拟退火算法是受物理学领域启发而来的一种优化算法，退火是指将合金加热后再慢慢冷却的过程中。大量的原子因为受到激发而项周围跳跃，然后有逐渐回到一个低能阶的状态，所以这些原子能够找到一个低能阶的配置。
算法一个问题的随机解开始，它用一个变量来表示温度，这一温度开始很高，然后逐渐变低。每一次迭代期间，算法会随机选中题解中的某个数字，然后朝某个方向变化。
算法最关键的部分在于：如果新的成本值更低，则新的题解就会称为当前题解，者和爬山法非常相似，但是如果成本值更高的话，则新的题解仍然可能会称为当前题解，这是避免局部最小值的一种尝试。
某些情况下，在我们得到一个更优的解之前转向一个更差的解是很有必要的，模拟退火之所以惯用，不仅是因为它总是解扼守一个更优的解，而是因为它在退火过程的开始阶段会接受表现较差的解，随着退火过程的不断进行，算法越来越不可能接受交叉的解，最后，它只会接受更优的解， 更高成本的题解，其被接受的概率由以下公式给出：
$$p = e^{(-(highcost - lowcost)/temperature)}$$

因为温度（接受较差解的意愿）开始非常高，指数将总是接近于0，所以概率几乎为1.随着温度的递减，高成本值和低成本值之间的差异会越来越来重要   差异越大，概率越低，所以该算法只会倾向于稍差的解而不是非常差的解：

```python
#filename : optimaization.py

def annelingoptimize(domain,cosf,T=10000,cool = 0.95,step = 1):
	#随机初始化值
    vec = [float(random.randint(domain[i][0],damain[i][1]))
              for i in range(len(domain))]
              
    while T > 0.1:
    	#选择一个索引值
        i = random.randint(0,len(domain) - 1)
        
        #选择一个改变索引值的方向
        dir = random.randint(-step,step)
        #创建一个代表题解的新列表，改变其中一个值
        vecb = vec[:]
        vecb[i] += dir
        if vecb[i] < domain[i][0] : 
        	vecb[i] = domain[i][o]
        elif vecb[i] > domain[i][1]:
        	vecb[i] = domain[i][1]
            
        #计算当前成本和新的成本
        ea = costf(vec)
        eb = costf(vecb)
        
        # 它是更好的解么？或是趋向最优解的可能的临界解么？
        if (eb < ea of random.random() < pow(math.e,-(eb - ea)/T)):
        	vec = vecb
            
        #降低温度
        T = T * cool
    return vec
```
Domian 是一个由二元组构成的列表，它指定了每个变量的最大和最小值，题解的长度与此列表的长度相同，人都有十个选择的话， domian中的项为 (0,9) 
#######随机搜索

```python
def randomoptimize(domain,costf):
	best = 99999999
    bestr = None
    for i in range(1000):
    	#创建一个随机解
        r = [random.randint(domian[i][0],domain[i][1])
            for i in range(len(domain))]
            
        #计算成本
        cost = costf(r)
        
        #同到目前为止的最优节进行比较
        if cost < best:
        	best = cost
            bestr = r
   return r
```

######爬山法
爬山法一个随机解开始，然后在其临近的解集中寻找更好的题解（具有更低的成本）。
情景： 一个人随机的被安置在山区，他想要走到最低点找水源， 可以选择任何一个方向，然后向着最险峻的斜坡向下走去，可以一直走下去，直到到达平坦或坡度开始向上的区域

```python
def hillclimb(domain,costf):
	#创建一个随机解，
    sol = [random.randint(domain[i][0],domain[i][1]) 
           for i in range(len(domain))]
    #主循环
    while 1:
    
    	#创建相邻解的列表
        neighbors = []
        for j in range(len(domain)):
        	#在每个方向上相对于原位置偏离一点
            if sol[j] > domain[j][0]:
            	neighbors.append(sol[0:j] + [sol[j] - 1] + sol[j+1:])
            if sol[j] < domain[j][1]:
            neighbors.append(sol[0:j]+[sol[j] + 1] + sol[j+1:])
        
        #在邻域中寻找最优节
        current = costd(sol)
        best = current
        for j in range(len(neighbors)):
        	cost = costf(neighbors[j])
            if bost < best:
            	best = cost
                sol = neighbors[j]
            #如果所有邻居之间都没有更好的解，则退出循环
            if best == current:
            	break
    return sol
```
爬山法的一个缺陷是 可能会陷入局部最小值， 解决方法是： 随机重复爬山法（random-restart hill climbing）,让爬山法以多个随机生成的初始解为起点运行若干次，以希望逼近全局的最小值，

######遗传算法
该算法的运行过程是：先随机的生成一组解，我们称之为种群（population）。优化的过程的每一步，算法会计算整个种群的成本函数，从而得到一个有关题解的 有序列表

* 精英选拔
对题解进行排序之后，一个新的种群 --- 我们称之为下一代被创建出来了，首先我们降档前种群位于最顶端的题解加入其所在的新种群中，我们称这一过程为精英选拔法（elitism）。新种群中的余下部分是由修改最优解后形成的全新解所组成的

有两种修改题解的方法：

* 变异
其中较为简单的一种称为变异 （mutation）,其通常的做法是对一个既有的解进行微小的、简单的、随机的改变， 本例中，完成变异只需要从题解中选择一个数字，然后对其进行递增或者递减即可。

* 交叉
 另一种方法称之为 交叉(crossover)或 陪对(breeding)。这种方法是选择最优解中的两个解，然后将他们按照某种方式进行结合，本例中实现交叉的一种简单方式是，从一个接种随机取出一个数字作为新题解中的某几个元素，而剩余元素则来自于另一个题解。

一个新的种群是通过对最优解进行随机的变异和配对处理构造出来的，它的大小通常与旧的种群相同，而后这一过程会一直重复进行---新的种群经过排序，又一个种群被构造出来了。达到指定的迭代次数，或者连续经过数代后题解都没有得到改善，整个过程就结束了。

```python
def geneticoptimize(domain ,costf,popsize = 50,step = 1,
                nutprob = 0.2,elite = 0.2,maxiter=100):
	#变异操作
    def mutable(vec):
    	i = random.randint(0,len(domain) - 1)
        if random.random() < 0.5 and vec[i] > domain[i][0]:
        	return vec[0:i]+[vec[i]-step] + vec[i+1:]
        elif vec[i] < domain[i][1]:
        	return vec[0:i] + [vec[i]+step] + vec[i+1:]
    
    #交叉操作
    def crossover(r1,r2):
    	i = random.randint(1,len(domain) - 2)
        return r1[0:i] + r2[i:]
        
    #构造初始种群
    pop = []
    for i in range(popsize):
    	vec = [random.randint(domain[i][0],domain[i][1])
               for i in range(len(domain))]
        pop.append(vec)
        
    #每一代中有多少优胜者？
    topelite = int(elite * popsize)
    
    # 主循环
    for i in range(maxiter):
    	scores = [(costf(v),v) for v in pop]
        socres.sort()
        ranked=[v for (s,v) in socres]
        
        #下一代从纯粹的生出者开始
        pop = ranked[0:topelite]
        
        #添加变异和配对后的胜出者
        while len(pop) < popsize:
        	if random.random() < mutprob:
            	#变异
                c = random.randint(0,topelite)
                pop.append(mutabe(ranked[c]))
            else:
            	
                #交叉  从优胜者（精英）中选择
                c1 = random.randint(0,topelite)
                c2 = random.randint(0,topelite)
                pop.append(crossover(ranked[c1],ranked[c2]))
       #打印当前最优解
       print scores[0][0]
    return socres[0][1]   #是最优解向量
```

######对于 遗传算法的 更进一步的应用是 一串编程

通常的工作方式是：
  竞争方面：
  以一大堆 程序 （称为种群） 开始， 这些程序可以是随机产生的，也可能是人为设计的（hand - designed），并且被认为是某种程度上的一组最优解， 然后这些程序会在一个由用户定义的任务中展开竞争。所谓的任务可能是一种竞赛（game） ，各个程序在竞赛中彼此展开竞争，也有可能是一种个体测试，其目的是要测出哪个程序的执行效果更好，待竞争结束之后，我们会得到一个针对所有程序的评价列表，
  接下来是进化方面：
  算法可以采取两种不同的方式对表现最好的程序实施复制和修改。
  
  * 变异
  算法会对程序中的某些部分以随机的方式稍作修改，希望产生一个更好的题解出来，
  
  * 交叉
  先降某个最优程序的一部分去掉，再从其他最优程序的某一部分来替代之， 
  
  这样的复制和修改会产生出很多新的程序来， 这些程序基于原来最优的程序，但是有不同于他们。
  
  在每一个复制和修改的阶段，算法都会借助于一个适当的函数对程序的质量做出评估，
  
  上面的创建新一代的过程直到终止条件才会结束，具体的问题不同，终止条件也会不同：
  
  * 找到了最优解
  * 找到了表现足够好的解
  * 题解在经历了数轮之后都没有得到任何改善
  * 繁衍的代数达到了规定的限制
  
  对于某些问题而言，如确定一个数学函数，令其将一组输入正确的映射到某个输出  要找到最优解是可行的，但是对于其他问题 如棋类问题， 也许根本不存在最优解，因为题解的质量严重依赖与对抗者采取的策略
  
  为了构造出能够用于测试、变异和配对的程序，我们需要一种方法能在python代码中描述和运行这些程序，这种方法必须是易于修改的， 它保证所描述的是一个实实在在的程序， 这意味着随机生成的字符串作为python的代码是行不通的。为了描述遗传编程中的程序，研究者提出了各种不同你个的方法，而其中应用最为普遍的树形表示法。
  
  大多数编程语言，在编译和解释时首先会被转换成一棵解析树， 树上的节点有可能是枝节点，但表了应用于其叶子节点之上的一种的操作，也可能是叶子节点，一个带常量值的参数。
  
  * 在pyhon中表现树
 现在可以在python中构造 “树状程序” （tree program） 了，这棵树是由若干节点组成的，根据与之关联的函数的不同，这些节点又可以拥有一定数目的子节点。这些子节点将会返回传递给程序的
参数，另一些节点则会返回常量，而那些最值得关注的节点则会返回应用于其字节点之上的操作。








#####梯度下降法中的步长确定方法（一维搜索）
一维搜索的主要结构如下：1）首先确定包含问题最优解的搜索区间，2)再采用某种分割技术或插值方法缩小这个区间，进行搜索求解。

当然这个搜索方法主要是适应单峰区间的

######1、 确定搜索区间
确定搜索区间一般用进退法，思想是从某一点出发，按某步长，确定函数值呈现“高-低-高”的三个点，一个方向不成功，就退回来，沿相反方向寻找。
步骤如下：

![][8]


######2.搜索求解
搜索求解的话，0.618法简单实用。虽然Fibonacci法，插值法等等虽然好，复杂，就不多说了。下面是0.618法的步骤。

![][9]

普通的0.618法要求一维搜索的函数是单峰函数，实际上遇到的函数不一定是单峰函数，这时，可能产生搜索得到的函数值反而大于初始区间端点出函数值的情况。有人建议每次缩小区间是，不要只比较两个内点处的函数值，而是比较两内点和两端点处的函数值。当左边第一个或第二个点是这四个点中函数值最小的点是，丢弃右端点，构成新的搜索区间；否则，丢弃左端点，构成新的搜索区间，经过这样的修改，算法会变得可靠些。步骤就不列了。

######2、不精确一维搜索
一维搜索过程是最优化方法的基本组成部分，精确的一维搜索方法往往需要花费很大的工作量。特别是迭代点远离问题的解时，精确地求解一个一维子问题通常不是十分有效的。另外，在实际上，很多最优化方法，例如牛顿法和拟牛顿法，其收敛速度并不依赖于精确一维搜索过程。因此，只要保证目标函数f(x)在每一步都有满意的下降，这样就可以大大节省工作量。

![][10]





[0]: http://blog.csdn.net/xianlingmao/article/details/7768833
[1]: http://my.csdn.net/uploads/201207/23/1343012077_5764.png
[2]:http://images.cnitblog.com/blog/381513/201303/26153621-4d06ee79f12a49eaa5de42981073a488.png
[3]: http://images.cnitblog.com/blog/381513/201303/26153640-864bf414ab3c4386af026c3bd69d47ef.png
[4]: http://images.cnitblog.com/blog/381513/201303/26153701-2d130c05a7494e54997f2fa6f0ae179d.png
[5]: http://images.cnitblog.com/blog/381513/201303/26153720-23928037e2f4472c84dce72959b42a69.png
[6]: http://images.cnitblog.com/blog/381513/201303/26153744-1b8fa518b83140d7ae08ae866023b32e.png
[7]:http://images.cnitblog.com/blog/381513/201303/26153811-910bff2dd0204d42a8ee8395844f27c9.png
[8]: http://img.blog.csdn.net/20131123183922312
[9]: http://img.blog.csdn.net/20131123184054890
[10]:http://img.blog.csdn.net/20131123185520562