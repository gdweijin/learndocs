互联网广告系统综述

[toc]
#####二 。 业务背景

广告一直是无处不在的，在古代，武大郎挑着他的大饼，在街上大喊：“卖大饼咧，又大又圆的大饼啊，只卖一文钱！”这也是做广告的一种方式。

到了现代更加多了，电视放到关键时刻，总要来点广告。

互联网兴起后，哪里都有了广告了。

###### 一、背景
* 1.1 前言
最近几年，机器学习、数据挖掘的概念风生水起，越炒越热了。很多年轻人浏览了几本数据挖掘相关书籍，就感觉自己会数据挖掘了。当年也是这么样的，学了一两个机器学习算法，就头脑发热地去找工作，结果根本就没几家公司要数据挖掘工程师，人家只要数据分析师。那一种狗血淋头的打击，真是满满的挫折感，从此再也不敢说自己会数据挖掘了。
在这总结一下在数据挖掘方面做的工作的总结，期望能帮助几位热血青年。
机器学习目前最佳的一个落地领域似乎还是互联网广告领域（个人自以为，各位可以为自己选一个爽的）。在互联网广告领域，机器学习方法，ACM中的一些精妙的方法，数学建模中的一些方法，都能用得上。刚好互联网广告也是互联网行业，最近这个行业也是在黄金期，那么学习机器学习的同学们确实迎来了春天。
随着互联网的发展，“计算广告学”这个概念也被各位大牛们炒得波澜壮阔，在北京中关村，找个地方喝咖啡都能听到有人在讲计算广告学。
作为一个互联网广告的从业者，也在这写写互联网广告的一些知识吧。去年有过一些总结，散散碎碎的，现在以新视角再去描述一次吧。 

* 行业与生态
 在博文《互联网广告综述之生态圈》中已经论述过这么样的一个生态圈了。只是当时没有想明白一些问题，经过最近以来的学习到的一些知识，慢慢发现了一些知识。
博文《互联网广告综述之生态圈》中论述的场景，是互联网广告业发展的一个大方向，就是一个可能的终极方向。但在目前的发展状态，大型的媒体、社交平台、论坛等，都具备了做互联网广告的能力，就诞生了一种情况，小型媒体和平台就把他们的流量放进了广告市场，由ad exchange帮他们售卖，大型媒体和平台的边缘流量（比较差的广告位）也放进了广告市场，大型媒体和平台的优质流量（核心流量）就由他们自己进行售卖。当然，广告主也乐意去选择这些优质流量，哪怕贵，但效果好。
那么就诞生了一些名词如“广告平台”，对于DSP，ad exchange，DMP这一个体系下，DSP就承担了广告平台这个角色；对于大型媒体和平台，他们自己内部的广告团队就承担了广告平台这个角色。
为啥弄这个名词出来？因为这个名词里面的工程师需要跟广告主，用户，老板三方利益都涉及。

* 商业模式
 大势说完了，名词也说完了，该说点深入点的了。由于是从广告平台的视角去看这个行业的，而广告平台的老板们肯定是追求赚钱的，那工程师的工作就是研究赚钱方法，但是赚钱方法这个名字太土了，就起了个好听的名字“商业模式”。
商业模式是有好几种的，从腾讯的广点通的技术博客上抄点东西过来吧。
先理解互联网广告的商业模式，业内常见的商业模式有四种：1） CPM，按展现付费；2）CPC，按点击付费；3）CPA，按转化付费；4）CPS，按销售分成。
这四种商业模式中，第一种对平台最爽，收了钱，只管展示出去，有没有人看，有没有人点都不用管。这种方式又被称为品牌广告。品牌广告对工程师的要求比其他模式的低，只要做好预订和分配系统就行了，雅虎这方面做得最好。预订分配系统要做好两个事情，一个就是预订，广告主过来后，选择好定向条件，输入要订多少流量，系统计算一下有没有这么多的量，够的话就广告主确认下单，钱就交了，广告计划就预订好了。流量预订系统要流量尽可能多地卖出去，但是不能太多，订的量太多了，投不够，要赔钱的。另一个是分配，订单下好了后，线上就要分配流量，一个流量要分配到哪个订单里面去，这个要求一些运筹学的东西（搞ACM的人比较擅长的）。分配系统也要弄好了，不然流量分配得不好，有些订单没投放够量，要赔钱的。
第二种CPC广告不一样了，按点击收费，无论投了多少次，广告主都不给钱，只有投出去后，用户点击了，平台才能收钱。
第三种CPA广告，无论投了多少，点击了多少，但是没有用户因为这个广告买了广告主的东西，广告主都不给钱，只有有用户通过这个广告买了广告主的东西，平台才能收钱（类似租房中介）。
第四中CPS，平台给广告主投了很多次，有用户通过这个广告买了广告主的东西，平台从广告主那里有分成（类似各种托）。
大家可以看到，第一种方式不用管投的效果好不好了，反正就是广告轰炸，只要广告投到了他们的人群上面去了，就行了，他们有钱，大大的给。用这种方式的一般都是那些有钱的广告主，如宝马等等，所以这种方式也叫品牌广告。
后面几种对广告平台来说都有效果的压力，因为投的人不对，没点击和转化的，收不到钱，所以这几种商业模式都叫效果广告。
从腾讯的广点通的技术博客上弄个图过来吧。
![][1]
容易理解，广告主最欢迎CPA模式，因为这种模式的广告投放效率最高，广告主不必为无效的展现和点击买单。然而，业内做CPA的广告网络（Ad Network）并不多，主要原因是转化数据难以收集。

#####三 、业务描述
前面说了互联网广告市场发展的一些现状，其中提到了品牌广告和效果广告，也提到了广告平台中涉及的三个利益相关方广告主，用户，广告平台老板。
由于本文是利用广告平台的工程师的视角描述的，就聊聊广告平台上的利益相关方的博弈吧。
当然，要注意的是，效果广告才有这三方博弈，品牌广告往往只有广告主和平台在博弈，用户方面考虑得比较少。
下面说的东西都主要以效果广告的视角描述的。

* 三国杀
 广告平台的工程师的视角，其实就是广告算法工程师的视角了，因为其他团队如产品，工程，运营团队，都没有需要直接利用代码来实现这三方利益的任务。换言之，广告算法工程师就是处于那个平衡三方利益的位置的。
下面看看这三方的需求。
 * 老板：赚更多的钱 
 * 广告主：更合适的受众，更高的转化率
 * 用户：我不喜欢的我不要  
 
 三个方面的利益其实不是一致的：平台老板想多赚钱，就要给用户投广告；广告主想要用最少的钱换最大量的转化；用户根本不想看他不感兴趣的广告。
这就让广告算法工程师很为难了

* 算法的角色 --- 制衡
 既然有了这样的任务，广告算法工程师自然也不能坐以待毙。三方利益不能同时最大化，那就只能在三方利益中取平衡点了，这个工作起个好听点的名字“制衡”。
下面看怎么制衡
 * 2.1 广告主
先说怎么满足广告主的需求——更适合的受众，更高的转化率。
关键点是怎么选择更适合的受众了。
广告主的要求是变化多端的，因为卖什么的广告主都有。广告主也有自己的一些经验，所以他们也大致知道什么样的人（潜在客户）适合投他们自己的广告。理想情况是广告算法工程师帮助广告主找出最合适的客户，只是广告算法工程师不可能一位一位用户地去问他们喜欢什么广告主吧。而且用户的兴趣变化多端，相关的广告主会很多，标注起来会非常复杂。
既然没办法做到极致，就只能做能做的事——准确地划分人群。
工程师划分人群后，这些人群就具备了一些属性，广告主在下单前，根据自己产品的特性去考察这些属性，去选择自己的广告受众，这个过程叫做“选择定向条件”。
这个过程就是广告行业的术语“定向”，这里先把一些通用的定向方式列一下，再说说广告算法工程师的工作吧，
常见的广告定向方式有后面几种：
   1. 人群属性定向。
   2. 上下文定向。
   3. 行为定向。
   4. 再营销。
   5. 相似用户定向。
   6. 地理位置定向。
   7. 其他如时间定向；设备定向；天气定向；语言定向。
   
   要满足广告主的这些定向方式，就考察广告算法工程师的头脑了，要做的事情其实很多的，如第一个“人群属性定向”，就说年龄性别这两个简单属性来说，很多平台都没有的，就要算法工程师用各种模型去估（其实有时候都是瞎估）了。其他的如教育背景、职业、婚姻状态、收入、消费能力、工作场所等等，有这些数据的公司很少，多数都是瞎估，估算方法五花八门，都是被逼出来的。但是这个跟三大利益方的需求有关，只好整出来。再有“行为定向”和“相似用户定向”，这两个就靠谱点了，毕竟用户行为可以总结出大致的兴趣来，相似的用户也能用机器学习方法弄出几分来。
这里只是综述，后面会有其他章节介绍广告算法工程师在定向方式方面的工作的。
 * 2.2 老板与用户
老板的需求是——赚更多的钱。
用户的需求是——不喜欢的东西不要，只看自己感兴趣的东西。
两个写在一起的原因是这两条往往是冲突的，一个用户不感兴趣的广告，出价往往比较高；而一个用户感兴趣的广告，出价往往不高。
而能产生上面所说的冲突的原因是，一个用户来了，会有很多广告主想向他投广告，这些广告有些用户喜欢，有些不喜欢；有些出价高，有些出价低。
这就带来了广告算法工程师的苦恼，怎么办？难道仰天长叹：“元芳，你怎么看？挖掘机技术哪家强？”
早有优秀的前辈找出了解决方法，有两个相关的方法：算分排序和扣费方法。
   * 2.2.1算分排序
算分排序这个东西能综合考虑老板和用户的需求，具体操作方式是，一个用户来了，对于想向这个用户投的广告，都打一个分，根据这个分进行倒排序，排在最前面的广告就是对这两方最合适的广告。
且看看每个广告算分公式:
Score=bid*ctr
其中的bid表示广告的出价。
而ctr的含义比较丰富，既表示了用户对广告的喜欢程度，也表示了广告的质量，还表示了这个广告的期望的点击率，还希望这个ctr跟广告真实的点击率也是一致的。这个ctr不是谁给出的，而是用一些方法（模型）估算的。这ctr估高了，会把出价不高同时用户也不喜欢的广告的分算得比较高，这样是不行的；估低了，出价一般高但是用户比较喜欢的广告的分算得比较低，没机会投出去，就会导致用户总是看到不喜欢的广告。既然这个ctr这么重要，自然也是广告算法工程师的工作的重中之重，后面有专门的章节介绍这个ctr的计算方式的，那是一个艰苦的战役。这里就把结果拿出来直接用了。
算分公式是用乘法，保证了出价高的广告分更高，也保证ctr高的广告分也更高；而光出价高，ctr特别低的广告分一般高，同时出价特别低，ctr比较高的广告分也一般高，从而更可能排名高的广告是出价一般高，ctr一般高的广告排名高了（两边不得罪）。
就这样，算分排序平衡了两方的需求。这也就平衡了收益和用户体验。
  * 2.3 老板与广告主
上面的描述说了老板与用户的关系，就是要平衡收益和用户体验，通过算分排序完成了。
还有一对冤家的利益需要平衡，就是老板与广告主，这事情比较诡异，因为这两家的问题也比较突出的，广告主想少花钱获取更多受众和转化；老板希望尽量多收钱，而且还希望长期多收钱，这也需要广告算法工程师提供一个平衡的方法（真是老鼠钻进风箱里，两头受气）。
优秀的前辈们总是有办法的，他们提供了扣费方法，下面抄一个过来吧。
   * 2.3.1扣费方法
有几种，广义一阶价格和广义二阶价格是被讨论得最多了。
广义一阶价格（GFP），就是广告主开多少价，在广告投放后就收多少钱。这样广告平台就会跟广告主进行重复博弈，在每一轮拍卖结束后，广告主会根据上一轮报价的情形决定下一轮的出价决策。这样就很容易出现问题，一开始广告主为了抢量不断抬价（价格攀升阶段），后面玩熟练了，大家一起压价（价格崩溃阶段）。这样广告平台就需要非常了解广告主的估计，否则，价格不断波动，流量会浪费很严重，广告平台的生意很容易就搞砸了。
广义二阶价格（GSP），这个二阶的意思就是下一位的出价，一个广告支付的钱是排在下一个位置的广告的出价，用术语来说就是：第i个广告位的广告每次展示或者点击（分别对应两种竞价方式，按展示收费或者按点击收费）所付的费用，等于第i+1个广告位的广告出价加上一个很小的值（一般是0.01）。
这里还是有两种。一种是竞价排序，根据广告的出价倒序排列，被点击的广告主付他下一家的费用。另一种是收入排序，根据期望收益最大来排序，这里的期望收益指的bid*ctr，被点击的广告主付的费用为bid(i+1)*ctr(i+1)/ctr(i)；后面的那个ctr有时候也可以用score代替，即扣的费用计算公式也可以是bid(i+1)*score(i+1)/score(i)，当然扣费不能超过广告的出价，也不能低于一个最小值（各个平台自己定义的）。
收入排序方式目前是最常用的，组内也正在用。这样的好处就是可以鼓励广告主优化自己的广告质量，只要某个广告比排在后面的广告质量高很多，扣费就会特别少，反之就扣得多。
说到这里，如果上面的工作完成得不错了的话（ctr计算得很好了），相关工作其实已经完成了。这是不是意味着广告算法工程师可以高枕无忧了呢？答案还是不行，因为三个利益方还会有各种要求，这个就依赖下面的业务策略来解决了。
 * 2.4 业务策略
上面说过，系统搭建工作完成了，广告算法工程师还是不能高枕无忧。有什么困扰呢？因为三个利益方的各种要求还是很多的。
下面列一些吧
   * 1、季末冲业绩
在每个季度的末尾，因为要发财报，要汇报等等，业务部门的压力会过来，就需要临时调整扣费策略或者排序方式来增加收入（各个公司不同）。
   * 2、聪明的广告主
一个新上线的广告，一般通过冷启动能获取一些投放量（就是开始的ctr会估得不准，就用一些平均的值去代替，从而让新广告有一定的量）。广告主都很聪明的，有些广告主就建大量的新广告计划，从而得到了大量的投放量，但是这个广告主的广告质量很差（点击率很低），大大影响了业务指标。这个问题是很久才排查到的，然后就对每一个广告限制了广告计划数，系统就恢复了正常。
   * 3、指标的牺牲
广告平台为了建立口碑，同时改善用户体验，需要对自己的广告进行质量把关。为了完成这个工作，就需要对低质量的广告（低点击率）进行一些打压策略，就是降低这类型广告的投放量，往往是通过对排序中的那个score进行打压得到的。打压的方式很多种，好用的方法就是根据这个广告的点击率与整个平台的整体点击率相除，得到一个ratio，这个就是打压的因子。
   * 4、用户的抱怨
对于大型媒体和平台来说，还是要收集自己的用户意见的。用户会抱怨看到广告，这个是没有办法的了，但是用户如果抱怨的是整天看到同一个广告，那就有问题了，这样是不行的。对于广告平台来说，可以对用户看同一个广告主的广告次数进行控制，让用户在一段时间内最多只能看到同一个广告主的广告若干次（各个公司不同）。这起码一定程度上减少了用户的抱怨。做得更好一点的，对广告进行归类（聚类，相似的广告聚到一起），对用户看同一类型的广告也有次数上的控制，效果也会更好一些。

  以上的这些业务策略肯定不是闲着没事想出来的，都是一些实实在在的线上问题排查的处理方法或者真的是被用户抱怨多了收集来的，这些真是经验。这可能也是广告算法工程师在搭建完系统后没有被老板赶走的原因。
一个广告系统的优化方向很多，经验有限也不能一一列举了。


#####三 、定向
所谓定向，就是广告算法工程师提供给广告主一些用户属性与条件，供广告主用来找到自己的目标人群的。
定向是很重要的，在古代，一个买大饼的武大郎，想必不会把大饼担挑到几十公里见不到人的戈壁滩去吆喝。一个卖草帽的老板，也不会跑到青楼一条街去吆喝。定向就是广告主选择自己的目标人群，避免造成“你喊啊，你喊破喉咙也没人理你”的尴尬场面。
这个功能可大可小，随便做做点简单的也许，好好做得很细也行，对小公司来说，投入产出比不见得会特别高，对大公司来说，可以投入大量人力来好好做，体现大公司风范。
在这个方面，机器学习的各种方法都可以用上，甚至可以不择手段。
为了能看到全面点的东西，先抄些别人总结的东西来吧，其实组内也没有做出这么多定向条件来。抄完后就说点自己组内做的。
* 一、广告定向方式综述
 * 1.1 广告定向方式
  常见的广告定向方式有以下几种。

   1. 人群属性定向（Demographic Targeting）
基于用户基本属性，如年龄、性别、教育背景、职业、婚姻状态、收入、消费能力、工作场所等做人群定向，相对静态，长期不变。
   2. 上下文定向（Contextual Targeting）
基于用户当前查询的query、浏览的网页、使用的 App 等语义分析结果定向，均为实时访问上下文。另外，有些人喜欢把移动设备、LBS 地点、天气也归入此类，个人更倾向于特指内容型数据，如文本、视频等。常见的定向属性有关键词（Google Adsense、Facebook、百度凤巢）、否定关键词（Google Adsense）、展示 URL（Google Adsense、百度网盟）、页面主题（Google Adsense）、行业分类（百度网盟）等。
   3. 行为定向（Behavioral Targeting）
基于用户历史行为数据挖掘用户兴趣，行为数据如网页浏览、网页点击、查询 query、UGC 内容（如微博、朋友圈等），一般需要区分长期、短期和实时兴趣。常见的定向属性就是兴趣爱好，依靠人工定义一套层次化的类别体系，有些平台还会按照时间段（Google Adsense、百度网盟）或者商业性（品友互动）进一步区分。
   4. 再营销（Remarketing）
常见的有到访再营销、搜索再营销、广告点击再营销等。其中，到访再营销需要用户访问过商品页面或者在商品页发生过某种预定义的行为（如收藏、下单、转发等），在广告投放时，广告平台为用户展示相同（直接查表）或类似（item-based、content-based）的商品；搜索再营销根据用户在搜索引擎中搜过的 query，在广告联盟网站上展示内容相关的广告；广告点击再营销则是依据用户点击的广告数据，为其展示相同或类似的广告。一般实时性要求高，效果好，但是用户覆盖少。
   5. 相似用户定向（Look-Alike Targeting）
侧重基于确定的一小波人群，圈出更大规模类似的人群，保证定向效果的同时，扩大用户覆盖。因为挖掘相似用户过程中，主要依据用户基本属性或兴趣（长期），更新频率不高。Google Adsense 将曾经到访过广告页面的用户作为基准定制人群，然后按照用户在 Google Display Network 上的页面访问行为衡量用户之间的相似性，以扩展更多用户；而 Facebook 需要广告主提交基准定制人群，比如 Email、Phone、Facebook Ids、App Ids，后台自动找到相似用户。
这块工作和 DSP 中的 audienceselection 非常类似。
   6. 地理位置定向（Geo Targeting）
移动互联网比较热门的定向，可以定位城市、商圈、学校等区域。
   7. 其他
    >* 时间定向（TimeTargeting）：一天中的不同时间段。
    >* 设备定向（DeviceTargeting）：如手机品牌、型号，操作系统，运营商等。
    >* 天气定向（WeatherTargeting）：对经常出现雾霾天气的北京，投放口罩、空气清新器应该是靠谱的。
    >* 语言定向（LanguageTargeting）：一般具有国际化市场的广告平台会提供，如 Google、Facebook。
    
  * 广告定向方式对比
   按照用户覆盖和定向效果两个维度，综合考量不同定向方式之间的关系，如下图所示：
   ![][2]
   
   横坐标是覆盖率，纵坐标是效果。不同类型的定向条件，效果不一样，覆盖率也不一样，如remareting，覆盖率低，但效果很好。
   
* 二、 广告定向方式数据生成
  上面说的那么多定向方式，一个公司全部实现的非常难，这里挑几个组内实现过的来说。
简单的，在多数的平台上，性别用户都会自己填，手机平台或者PC能从前端直接取到，根据日志再统计一下就够了。
下面说些需要做点工作的。
  * 1 、年龄
   年龄很重要，广告主很需要。对于一个平台来说，有部分年龄是可以准确获取到的。
还有很多未知年龄的用户，可以跟这个用户的好友，做一个平均值，这样，很多用户就有了年龄，这个方法虽然很简单，却很凑效，其他看来不少paper，倒也没发现哪个更靠谱了。
  * 2、 兴趣
  基于用户历史行为数据挖掘用户兴趣
  首先要做的工作是定义兴趣，对于媒体来说，简单的方式就是用网页（频道）来定义。
每个网页一般会打一些标签，简单的可以通过运营团队给这些网页（频道）标一些商业相关的兴趣标签（这个可以使用机器学习方法自己来搞，就是统计看每个频道的用户对各类广告的点击率，广告自己是有商业相关信息的，那么就能得到了各个频道跟各个兴趣的相关度，就把这些相关度作为这个频道的兴趣向量）。
网页被定义兴趣标签后（机器学习挖掘出来的是向量），用户会在平台上浏览一些网页，就直接把这个网页代表的兴趣标签（或者是向量）分给这个用户。计算一个用户的兴趣时，就把他最近一段时间看过的网页的兴趣向量累加（标签就用one hot表示），当然要对时间做一些衰减，很多天前看的，兴趣会被减弱，权重小点；最近几天看的，这个权重就大点。
这样用户就有了一个兴趣向量，再根据一些归一化的方法，把兴趣向量归一成一个全局的，就得到了用户兴趣向量，然后根据阈值选取，就得到了用户的兴趣。
 * 3、 关键字
 跟兴趣类似，首先对网页分词，得到每个网页的词。利用topic model选择topic 明显的优质词，再根据运营或者某些方法得到的一批的商业词（跟广告主有半毛钱关系的词），过滤每个网页的里面的商业词，得到了每个网页都用若干个商业词表示。
 计算一个用户的关键词时，就把他最近一段时间看过的网页的商业词分给该用户。
分完后每个用户都有了一大堆的关键词（有可能重复），利用tf-idf对每个关键词都弄出个权重来，再根据阈值选取，就得到了用户的关键词。
 * 指定页面的用户
 用户会浏览过很多网页，其中有些是广告主的主页。
这里就可以来些大招了——word2vec。用户浏览过的网页可以用一个id表示，那么每个用户就有了一串的id（表示这个用户浏览过的网页），把这串id当作一句话。那么多个用户的浏览记录，就有了多句话。这么多句话，就能作为word2vec的输入了，等word2vec算法跑完，每个网页id就有了一个向量来表示了。
每个id的向量本身每一维没啥意义（目前找不出来），只有他们的距离有意义。
广告主过来下单的时候，哪个页面跟这个广告主的主页最接近能计算出来的，那么就可以事先计算好每个广告主最相似的页面，这时展示给广告主一些勾选项，让广告主选择指定浏览过某页面的用户投放。
这就是指定页面用户定向条件的挖掘方法，想看多点的话看另一组word2vec的博文的应用篇。

* 三、 广告向线上架构
 ![][3]
经过广告算法工程师的工作，利用数据仓库和集群计算，离线完成用户的定向条件的挖掘后，其他团队会根据数据建立索引。
当广告主过来下单的时候，可以查询他的定向条件覆盖的人数以及历史售卖情况，根据这些信息广告主进行出价和下单。
广告主下单后会建立广告计划，广告计划以及定向条件会加载到存储器。
离线挖掘好的用户定向条件也会加载到线上存储器。一个用户过来后，线上服务会查询广告计划的定向条件，也会查询用户的profile，根据这两个东西的匹配来筛选适合投给这个用户的广告计划。
然后剩下的就是算分排序，扣费等等事情了。后面的博文会讨论。


#####五、 体系架构
前面几篇博文都说了很多业务架构方面的东西，顺便说了一些用户基础信息的挖掘相关的事情。那些很多都已经被大神们说得淋漓尽致了，除了定向中说的那几个定向方法以外。
下面就开始一些跟技术相关的东西了。

* 1.1 前言
在说了这么多技术无关的东西后，是要来点有技术性的东西了。
这系列的博文好像看起来并不能让很多人看的爽，因为没啥公式与技术相关的东西。可以想象到的是，大部分人花不了5分钟就看完了，觉得没啥含量。只是这些东西才是一个广告产品重要的东西，也是老板关心的东西，而用什么模型，什么挖掘手段，怎么去估ctr，真没有哪位老板会关心。
工程师思维不是那么有全局观的，技术也不能一头钻着。广告算法工程师需要更广阔的视野，去看到更多的可能性，更多的增长点。
这话还是很客气和空虚的，用人话来解释一下：想要赚钱，把前面那套东西搭起来，就能赚不少钱了，再让运营和销售多拉点有钱的广告主进来，那钱就赚得更多了；而用什么技术去预估ctr，用什么模型，用哪个大数据，都只是一些辅助手段，没有前面的那些工作，这些都只是镜中花、水中月。一个广告业务会因为出现了新的业务售卖形式获得业务指标大幅度的增长，但不会因为用了一个什么模型有翻天覆地的变化。再好的ctr预估、再好的模型、再大的数据，广告业务设计得很差，照样赔本。广告算法工程师拼了老命提升的一点点业务指标（点击率和收入），可能把流量换种方式售卖就达到了，而且广告主掏钱掏得爽爽的，用户也不反感，就像请第三方公司挖掘出广告主的潜在客户，直接让广告主高价来买这些流量，这样广告主满意了，用户也觉得还不错。
人话说完了，继续一些套话。广告算法工程师要注意对业务的掌控能力，看出在整个业务系统需要在哪个点发力，才能得到可观的业务指标提升，而不是一味地优化模型与特征。广阔的视野，能帮助看到业务的发力点，甚至能看到从当前业务中催生一个新业务，这样的广告算法工程师才是合格的。
这一段话也就是为了给自己前面那几篇博文加点回头率罢了，下面开始系统方面的东西了。

* 广告业务系统架构
 为了让各位对系统有一个全面的理解，这里把整个系统的架构列出来。
![][4]
一个用户过来后，这个广告请求会进入到广告投放平台。广告投放平台会读取一些索引，决定要不要进行投放，决定投放后，广告投放平台会读取广告主服务页推送过来的广告计划，做一些频次上的控制，再把剩余的广告交给线上定向模块。线上定向模块从线上存储器读取用户的profile数据，根据每个广告计划的定向条件去筛选，筛选剩下的广告计划就是适合投这个用户的广告；再对筛选剩下的广告，做一个比较粗的选取，选择其中质量较高的返回给下一个模块，这个工作由线上定向模块完成。
线上定向模块过后，剩下的是相对优质的若干个广告，开始对这若干个广告进行预估ctr，预估ctr过程中需要去线上存储器读取特征，一般还需要本地加载的一个模型。当ctr预估完成后，就进行算分排序，计算扣费，再加上一些业务策略，从而选出最合适的若干个广告，返回给广告投放平台。算法排序和计算扣费的方式在上一篇博文里面描述过，不多讲。
广告投放后，会产生日志，日志会通过日志收集系统收集到数据仓库。
广告算法工程师会从数据仓库里面获取各种投放日志，提取特征，把特征导入到线上存储器；还会根据投放日志，生成训练样本，训练模型，把模型推送到线上服务器，由线上服务器进行加载来给预估ctr使用。
技术实力强大的公司，还能进行在线学习，就是模型随着投放数据的不断产生，不断更新的，这个对工程能力要求很高。

* 1.3 注意点
上一节说的那个系统，很多可以由兄弟团队帮助搭建，但是，有两个点需要注意的。
第一个就是离线训练模型，这里面文章很大，大公司能用自己弄的mpi并行计算集群搞得很牛逼。然而不是每个公司都是大公司，也不是每个组都具备这样的技术实力，那就带来了问题，早期的公司如何快速实现系统的搭建？
在这个时候，工具论是个绝对可行的方法，如mahout，或者说vw。其中mahout可以有random forest，而vw有logistic regression，这两种模型在广告技术上是用得比较广泛的了，尤其是logistic regression，很多公司都在用。单机是很难达到要求的，并行计算是很重要而且要快速实现的，所以选择一个好的工具，非常重要。
第二个就是线上存储系统，离线特征的设计，如何方便存取也很重要。因为线上存储器空间有限，不可能无限扩展，有些特征如果不做区分，所占的空间将非常大。为了缩减数据体积，对特征做一些清洗，归并操作非常重要，这些也很考验数据挖掘工程师的经验。

#####六 、 模型
经过几个博文的啰啰嗦嗦，又是业务又是定向又是系统架构的，给各位的感觉都是在描述一些外围的东西，真正核心的东西还没说到。对于心急得如干柴烈火的热血青年来说，似乎一直在各种前戏，一直没感受到提抢上阵的快感。
就算这么急，这还是得说——在广告算法领域，如果说ctr预估是包子馅的话，前面那些东西就是包子皮，直接吃包子馅，不见得是很正确的吃法。
下面就说说大家喜闻乐见的模型吧。

* 1.1 准确估计ctr的意义
 得从前面的算分排序那一节说起了。
对于一些大型媒体行业平台，当时就说了ctr的估算要求比较准确，这ctr估高了，会把出价不高同时用户也不喜欢的广告的分算得比较高，这样的广告就排在了前面，这样广告平台既收不到钱，也讨不到用户喜欢；但ctr估低了，出价一般高但是用户比较喜欢的广告的分算得比较低，没机会投出去，用户就会总是看到不喜欢的广告，对媒体来说，这个最终也会导致用户的流失，照样赔了夫人又折兵。
对于广告生态圈中的DSP来说，同样DSP需要评估流量质量，如果发现一个流量的质量很高，就开高价去竟争这个流量；如果流量质量低，就开低价去竟争。如果评估得太高，出很高的价钱拿到了质量很低的流量，那就达不到广告主的要求，会亏钱；如果评估得太低，一直拿不到流量，没办法赚钱。评估流量质量，说到底了是预估一个流量的ctr。
说到这份上，总该明白一个问题了吧——估准ctr非常重要。这个就是广告算法工程师的工作的重中之重。
用另一个方式理解ctr，就是一个用户点击某一个广告的概率，点击的概率大，意味着越喜欢这个广告，用户越喜欢的广告，广告的质量自然可以认为是比较高的。
怎么算是估准了呢？举个例子，假如1万个人对同一个广告预估了1w个ctr的值，ctr的值当然有高有低了，如果这1w个人点击这个广告总共100次的话，同样也希望这1w个值的累加大致是100，这样才算估准了。但是，但是要注意的是，在这1w个值里面，那100个点击的人估算的值要明显比不点击的人要高，这就叫分开了，这才算是估得比较好的，如果人人都是大致0.01的话，也可以算是比较好的预估（因为跟真实的很接近），但是就没那么具备区分能力了，在有些业务下面，就不容易发挥更多的用处。
要估准ctr的意义说完了，就开始谈谈模型了。

* 1.2 为啥需要模型
 预估一个人对一个广告的ctr，不可能是一个广告算法工程师在那里看着，来一个广告请求就估计一下，给个决定，这样人累死，估计得也乱七八糟，还效率不高，一天撑死了估计个几十万个请求，不得了了。
只能用机器来估，但是机器是很笨的，只能进行简单的规则运算，这些规则还必须提前指定。如果人工指定这些规则，如30岁用户点击匹克篮球的广告概率是多少，男性的用户点击匹克篮球的广告的概率是多少，年龄和性别在总的ctr预估里面占多少比重等等，需要大量的先验知识，而且还不能根据实际情况变化，往往有问题。而且规则往往是有组合的。这个方法比用人估计好很多了，但还是很原始。
这时候数学家们就来劲了，直接看和简单规则不行，复杂规则可以啊，而且复杂的规则可以用函数来拟合啊，而且上面的那些规则都可以用统计方法得到，用函数把他们组合起来也可以啊。
数学方法就这样引进来了。
有两个相关的方面，一个是统计方法；另一个就是拟合一个函数去组合规则，这个函数就是模型。
用数学的方式来表示对点击率的预估，做的工作可以用下面的图来描述。
![][5]
统计方法怎么用呢？如可以统计过去投放过的记录中，30岁的用户点击匹克篮球的广告的点击率是多少，这个数据直接就能根据投放日志统计出来；再统计男性的用户点击匹克篮球的广告的点击率是多少，这样前面的两个东西就得到了。
但是知道这两个点击率，可以认为是两个规则；但这还不够，还需要知道这两个点击率在评估这个人点击匹克篮球的广告的概率中分别起什么作用，这就是规则的组合。这两个点击率加起来不行，相减也是不行的，加权累加可能是一种办法，但是这样行吗？还有怎么加权呢？用一个函数去组合这些规则就是很好的解决方案。为了描述的方便，我们用数学的方法来描述这两个规则，把这两个点击率（也就是规则）称为特征，用一个向量x=(x1,x2)来统一表示，其中x1表示30岁的用户对匹克篮球的广告的点击率，x2男性的用户对匹克篮球的广告的点击率。
问题就转变成了利用一个函数把向量x转变成用户对匹克广告的ctr了。这个函数就是模型，用数学的方法来描述就是完成上面的图中函数f的形式，这个函数f的形式确定了，就有了ctr=f(x)。
可以看到的是，利用模型是避免了人工规则扩展的困难，也使得每个ctr的计算变得可以用机器经过一些计算就可以完成，从而达到互联网在线服务的标准。
在传统领域也有些广告主利用先验知识做ctr预估的，就像是派传单，也要先看看哪个路人更容易接才派出去的；又比如化妆品促销活动，活动大使们肯定是找街上的一些女生来参加他们的活动，只有女生才更可能乐意参加他们的活动，这些都是一些ctr预估活动在起着作用，但是这个是人用了自己强大的大脑和先验知识来完成的，互联网在线服务要求并发高，务必要估得多而且快。想象一下行人密集得像地铁里面一样，而且都是百米冲刺的速度从派传单小哥或者活动大使面前经过，他们还怎么做生意？
所以模型加上人和广告对的向量表示，才能完成互联网的高并发与高速度的需要。

* 1.3 用什么模型
 上面说到了那个函数f就是模型，由于它的工作很复杂，那么形式应该是很复杂的，但是太复杂的模型不利于扩展，就用简单的形式来。经过工业界长期的工作，认为下面的形式是比较有效的。
 
 $ f(user,ad) = \frac{1}{1+e^{-w^Tx}}$
其中x是上面的那个x，w也是一个向量，表示的是x的每个特征的权重。这个w每取一个值，对相同的user和ad对就能得到一个预估的ctr，在f的形式已经确定的情况下w也可以称为是模型，因为它能根据x的取值，也就是特征的取值来决定ctr，也就是，f的形式主要是由w来确定的。
那么w这个向量的每个特征取值就变得很重要了，这个w的每个特征的值也可以由人工指定，但是上面说过了，需要大量的先验知识，而且特征会特别多，如上面还有地域，职业，学校什么的，可以搞到成千上万的特征，人工指定没办法做到周全。所以这个权重的是要用一些方法来让机器自己学习到的，这个过程称为训练，这个训练过程还不能只根据一个记录user和ad对来训练，要根据很多对来训练。每个展示记录就是一个对，根据历史的一段时间内的展示记录，能有很多的数据对可以进行训练。
说到了训练要用很多数据，但是这样说不够数学化，机器也做不了。只有把训练描述成一个数学问题的形式，机器才能接受。
很多年前最优化课程的老师说过，所有的问题都可以转化成一个最优化问题，当时听不懂也不知道为啥，现在才明白，计算机时代都只能这么来的，问题就是怎么构建那个最优化问题，就是几乎所有的算法工程师的工作，各种大牛们发表的paper都可以总结成在构建什么样的问题和怎么解这个问题。
现在有待解决的事情就是把权重向量w的每个特征的计算出来，拥有的条件是一大堆的x和这个x对应的用户的反馈：点击或者不点击。

* 1.3 模型的求解
上面描述了函数f的形式，以及权重向量w的意义，模型求解的意思就是把权重向量w的每个特征的计算出来，能依赖东西只有一大堆的x和这个x对应的用户的反馈。
数学家们也对这样的问题有了很好的办法。且看怎么构建一个最优化问题。
数学家认为总体的历史展示与点击数据符合一个伯努利分布，训练过程称为是拟合这个分布的过程。一次广告的展示是否被点击（每次展示被点击的概率可能不一样）是一个伯努利试验，用户点击这个广告表示伯努利试验成功，否则表示伯努利试验失败；对多个用户展示多个广告的过程是一个伯努利过程，每次伯努利试验成功的概率就是上面的f(user,ad)的值。为了方便描述，改变一下f的写法，用下面的方式表示
![][6]
其中y=1表示这个展示被点击了，y=0表示这个展示没有被点击。
到这个时候，就要出动极大似然估计了。极大似然估计的意思是已经出现的情况，发生的概率是最大的。怎么理解呢？三个人去打靶，打中的概率分别是p1、p2、p3。用二进制的方式表示是否打中，如010表示中间那个人打中，那么可能会发生8种情况：000,001,010,011,100,101,110,111。这8种情况发生的概率分别是(1-p1)*(1-p2)*(1-p3),(1-p1)*(1-p2)*(p3), (1-p1)*(p2)*(1-p3), (1-p1)*(p2)*(p3), (p1)*(1-p2)*(1-p3), (p1)*(1-p2)*(p3),(p1)*(p2)*(1-p3), (p1)*(p2)*(p3)。假如这8个概率中p1*(1-p2)*(1-p3)最大，让人去预估打靶的结果，各位都应该认为是100这种情况，因为最符合常识的。
极大似然就是把这种情况反过来用了，意思是：打靶的结果是100这样的情况，但是p1、p2、p3还在估计中，那么无论p1、p2、p3估计出来什么值，都要保证p1*(1-p2)*(1-p3)最大。
那么在上面这种情况下，很自然地用极大似然构建最优化问题了。用似然函数表示上面的那个伯努利试验过程，得到整个伯努利试验的似然函数（也就是事情发生的联合概率）
![][7]
下面的那个式子是对数似然，是为了方便计算加上的。
回到打靶的那个说法，要保证已经发生的事件那个概率最大，在这里就变成让似然函数取得最大值了，这样最优化问题的优化目标就有了，就是求似然函数的最大值，刚好每个x对应的h(x)都带着w，那么就可以把w当成要求解的变量。
就这样，优化目标有了，要求解的变量有了，整个最优化问题就建立了。
有人可能会注意到有可能同一个x（特征完全相同）的情况下可能会出现两个不同的点击结果（一次点击，一次不点击），这个情况就类似抛硬币一样，假如这个硬币正面向上的概率是0.6，抛出去，依然会有若干次会反面朝上。
这个会不会影响模型的构建呢？这时候就该统计分布的知识出马了，注意极大似然的目标依然是进行分布的拟合，算的依然是概率，一个事件的发生是按照概率来判断的，极大似然估计计算的依据其实是概率，而不是某一次伯努利试验是否成功，所以对于模型的构建来说是没有问题的。哪怕这个问题推到极致，所有x都一样，那么得到的结果就是h(x)刚好接近总体点击率，这依然是一个好的模型，只是，可能用其他方法也能得到同样的结果罢了。
拟合分布跟计算一个分类器（判别模型的决策面）不一样，对于一些构建分类决策面的模型来说，如果同一个向量同时落在决策面的两边，有可能会让模型的训练变得有问题。这个问题等具体想清楚了，再来解释。
剩下的就是求解的方法了，这个就是最优化的知识了，具体可以看其他博文。
这整个问题就是logisticregression的问题构建和求解过程。有关logistic regression，很多大神都刷了无数博文了，就不多献丑了。

  * 1.3.1 正则化
  正则化是一个机器学习通用的技术，目的是让w的每一个特征都不能太大，同时保证整个w所有特征都的绝对值都不特别大，总的来说就是避免产生特别不好的模型。
加完L2正则的优化目标如下
 ![][8]
 加完L1正则后的优化目标如下：
 ![][9]
其中L2和L1是两种不同的正则化技术，区别具体可以看其他博文。
  
  * 1.3.2 求解工具
   这个是多出来的东西，因为解上面的最优化问题可以有通用的解法SGD和BFGS。
但是前面的博文说过，找一个工具是很重要的，我们用过的比较好的工具就是vw。
Vw这个工具有几个优点如下
   1. Vw这个工具可以前期先用SGD跑出一个接近最优解的解，再用BFGS进行微调，得到尽可能的最优解。
   2. vw可以直接在hadoop集群上进行并行训练，避免了很多数据转移的工作。
   3. vw非常快，几亿的训练样本一般一个小时以内就完成，网络开销也不大，因为传输的东西很少。

  * 1.3.3 在线学习
 在线学习就是把模型在线上实时更新，投放了一个广告，就马上得到一个样本，利用这个样本去更新模型（SGD的方式）。
这样的话，模型是在线上训练的，所以也叫在线学习。

 * 模型架构
 从模型视角看，系统架构是下面的样子的。
 ![][10]

* 1.5 优点
  除了logisticregression，还有很多其他的模型可以选择的，如random forest、gbdt。这些模型应用起来可能会有一定的效果提升，但是相比logistic regression来说，还是没有具备那么高的扩展性。
下面列些优点看看。
和逻辑回归算法本身的很多特点有关的，例如：
1、变量范围是[-∞ ,+∞]；同时和其他“广义线性回归”相比，值域是[0,1]，因此形式上类似一个概率函数，适合分类问题；
2、可扩展性好，适合海量的特征；训练工具多样、可选
3、online learning，能够进行增量学习；
4、线性模型，解释性强。
这些优点都让logisticregression在做ctr预估的时候特别有优势，尤其是可扩展性，可以简单地增加特征，不需要太多的工作。

* 1.6评估
评估模型效果的方法有很多，如：
1. AUC，从排序的角度评估模型预估效果；
2. MAE（Mean Absolute Error）/MSE（Mean Squared Error），从准确率的角度评估模型预估效果；
3．OE比，就是预估的平均ctr与真实的ctr的比值，越接近1越准



#####七、 特征
描述完系统，模型等方面，就到了花费互联网广告算法工程师的最大精力的点了，就是特征工程，这是一个持久战斗的点。
流程复杂，而且各种机器学习的方法都可以在这里用上，有效果，有产出，有指标。当然，玩砸的也不少，打击总是很多的。
前面那么多的工作，都可以在系统搭建完成后，变化都不会特别大，剩下还可以变化的，就是预估ctr的时候的那个x了，这个x就是由特征组成，对ctr预估起到决定性作用的是选用的特征。
下面就特征工程的一些相关的点说一下。
特征工程真是艰苦的战役。包括想特征，特征生成，分析特征，特征加工，离线指标评估，线上效果评估，特征上线等，中间夹杂着各种工作。
下面一一来说一下吧。

* 1.1 想特征
什么样的特征适合用来预估ctr？这个问题是很多广告算法工程师的需要考虑的。
机器学习算法最多会大谈模型，对于特征的讨论很少涉及。真正的应用中，多数数据挖掘工程师的工作都是在想特征，验证特征。
想特征是一个脑力加体力的活，需要不少的领域的知识，更让人郁闷的是，工业界并没有一整套想特征的办法，工业界有的只是验证特征的办法。对于互联网广告业，就简单说说通用特征怎么来的吧。
首先说年龄这个特征，怎么知道它跟点击率有关系？现在直观的解释是，年轻人普遍喜欢运动类的广告，30岁左右的男人喜欢车，房子之类的广告，50岁以上的人喜欢保健品的广告。可以看到，选择年龄作为特征的理由是基于对各个年龄段的人喜欢的不同类型的东西的一个粗略的划分，是一个很主观的东西。
再说性别这个特征，直观的感觉是，男性普遍喜欢体育类的，车类的，旅游类广告，女性普遍喜欢化妆品，服装类的广告。这也可以看到，选择性别作为特征也是基于相似的理由，就是认为男性和女性大体会喜欢不同的东西。
对于地域这个特征，这下就学问多了，华南的人在比较喜欢动漫和游戏，华北的人喜欢酒品和烟？
在广告方面的特征，广告的图片大小，广告前景色背景色真的能影响人的点击吗？这其实都是一种猜测。图片里面是一个明星还是一个动物之类的因素也可以考虑。
总之，想特征的这个事情基本没多大谱，只能天南地北地想象，还要多了解各行各业的知识，以便想到更多的特征，哪怕某个特征跟人关系并不大，也得好好验证一番。这基本上跟男人为回家晚想借口一样，得有借口要想着怎么解释得好听点，没借口就要想借口。
想到了特征，就要分析、验证和进行判断。

* 1.2 分析特征
 再说年龄这个特征，怎么知道它跟点击率有关系？
只好去看看每个年龄段的人在各个广告上面的表现，比如经过跑数据分析，发现20~30岁之间的男性用户对车、房子之类的广告点击率比较高，而50岁以上的用户对保健品的广告点击率比较高。这就有了区分性了，说明年龄这个特征是对点击率是有预测能力的。
再说性别这个特征，去把每个性别对各个广告的点击率跑出来。根据结果，发现男性用户体育类的，车类的广告点击率比较高；而女性用户则对化妆品，服装类的广告点击率比较高。这就说明了性别这个特征对点击率是有预测能力的，因为有区分性。
实际分析过程中发现，性别这个特征比较有效，手机平台这个特征也比较有效，地域和年龄这两个特征有一定效果，但没有前两个那么明显，跟他们的使用方式可能有关，还需要进一步挖掘。
实际使用中也发现，实时广告ctr这个特征也很有效，这个特征的意思就是当前的广告正在投放，已经投放了一部分了，这部分的点击率基本可以认为是这个广告的点击率了，也可以认为是这个广告的质量的一个体现，用来预估一个流量的ctr是很有效的。

* 1.3 特征加工
 想到了特征，分析过了，发现是有效的，就想直接上线？没那么容易，对于很多特征来说，还是需要经过加工的，因为很多特征在加工后在线上的效果提升都很明显（当然，没加工过的特征也能起到一定的效果，只是没有发挥最大作用而已）。
特征加工目前用到三个主要的工艺：二值化，交叉，平滑，离散化
  
  * 1.3.1二值化
假设暂定有实时广告ctr，用户年龄，性别三个特征想要使用。
反馈ctr是一个浮点数，直接作为特征是可以的，假设1号特征就是反馈ctr。
对年龄来说就不是这样了，因为年龄不是浮点数，而且年龄的20岁跟30岁这两个数字20,30大小比较是没有意义的，相加相减都是没有意义的，在优化计算以及实际计算ctr是会涉及这两个数字的大小比较的。如w.x，在w已经确定的情况下，x的某个特征的值是20，或者30，w.x的值相差是很大的，哪怕用逻辑化公式再比较，得到的值也是比较大的，但是往往20岁的人跟30岁的人对同一个广告的兴趣差距不会那么大。解决这样的情况的方法就是，每个年龄一个特征，如总共只有20岁到29岁10种年龄，就把每个年龄做一个特征，编号是从2到11（1号是广告的反馈ctr），如果这个人是20岁，那么在编号为2的特征上的值就是1，3到11的编号上就是0。这样，年龄这一类特征就有了10个特征，而且这10个特征就是互斥的，这样的特征称为二值特征。
对于性别来说也是，两种性别，分别编号到12、13号特征上就完成了二值化了。
  
  * 1.3.2交叉
二值化看起来就能解决两个特征的差没有意义的问题了，但是够了吗？
比如一个人是20岁，那么在编号为2的特征上面，它一直都是1，对篮球的广告是1，对化妆品的广告也是1，这样训练的结果得到的编号为2的权重的意义是——20岁的人点击所有的广告的可能性的都是这个权重，这样其实是不合理的。
有意义的应该是，这个20岁的人，当广告是跟体育相关的时候，它是一个值；当广告跟保健品相关的时候，它又是另一个值这样看起来才合理。
因为特征需要根据人和广告的关系不断变化，才能使得一个人对不同的广告预估出不同的ctr来，如果特征不能跟着广告变化，那么一个用户对所有广告都预估出同一个值来，也是不行的。
基于跟上面同样的道理，性别这个特征也是一样的，假如也做了上面的离散化操作，编号是12和13,12是男性，13是女性。这样的话，对于一个男性/体育广告组合来说，编号12的特征值为1，男性/化妆品的组合的编号12的特征值也是1。这样也是不合理的，主观看过去都不合理。
怎么做到合理呢？以上面的性别的例子来说。编号12的特征值不取1，取值为该广告在男性用户上面的点击率，如对于男性/体育广告的组合，编号12的特征的值为男性在体育广告上面点击率，这样，编号为12的特征就变成了一个浮点数，这个浮点数的相加减是有意义的，这个浮点数的值越大，意味着这个性别的用户对该广告越感兴趣。这样过后，同一个用户，对不同的广告主，编号为12的位置的值都不一样了。而且这样可以不用编号为13的特征了，直接拿性别/广告的组合的点击率作为编号12的特征的值，两种性别都考虑到了。其实也就是说，经过组合后，年龄和性别各自又变回了一个特征，这个特征的值会随着不同的广告变化的，这个值跟广告有关。
这样的做法称为特征的交叉，现在就是性别跟广告的交叉得到的特征值。还有很多其他的方式可以进行交叉，目前应用起来效果比较好的就是广告跟性别的交叉特征，广告跟年龄的交叉特征，广告跟手机平台的交叉特征，广告跟地域的交叉特征。如果做得比较多，可能会有广告主（每个广告都是一个广告主提交的一个投放计划，一个广告主可能会提交多个投放计划）跟各个特征的交叉。
  
  * 1.3.3平滑
 经过上面的处理，很多特征变成了交叉的特征，而且特征值是一个广告过去一段时间的点击率（ctr）。
这个值是一个浮点数，计算的方式是交叉特征下的历史点击数/历史展示数，用字母表达是click/pv。
这个往往是很多问题的，如广告只投放了一次，就被点击了一次，点击率就是100%了，这个值是相当大的，只是肯定不可信，因为点击率一般百分之几就不得了了；又比如广告投放了100次，点击了1次，点击率1%，这样又可信了吗？假如pv为0呢？难道点击率就无穷大？
关于这个问题雅虎出了个paper，能很好地解决这个问题，是用贝叶斯学派的方法的。
首先两个假设。
假设一，所有的广告有一个自身的ctr，这些ctr服从一个Beta分布。
假设二，对于某一广告，给定展示次数时和它自身的ctr，它的点击次数服从一个伯努利分布 Binomial(I, ctr)。
如果用r表示点击率，I表示展示，C表示点击。这两个假设可以用下面的数学表示。
![][11]
根据这两个假设，假如已经有了很多个广告投放数据，I1,C1,I2,C2……In,Cn，就可以根据这些投放数据列出似然函数
![][12]
求解这个极大似然问题，得到两个参数alpha和beta，然后每个广告的点击率就可以利用这两个参数计算后验ctr（平滑ctr）了，公式如下：
r=(C + alpha) / (I + alpha + beta)
有了这个技术，上面说的那些交叉特征的特征值都用这个技术平滑了一下，就避免了出线1.0或者正无穷这种这么病态的特征值，因为一般都是很小的特征值。
事实证明，平滑技术很有效。

  * 1.3.4 离散化
  假设还是实时广告ctr，用户年龄，性别三个特征，经过上一次交叉和平滑，现在得到了3个特征值，实时广告ctr编号为1，年龄与广告交叉特征编号为2，性别与广告交叉特征编号为3。现在就三个特征了了。
这三个特征直接训练logisticregression模型，可以吗？可以的，但是线上效果并不好。为啥？这倒是个问题。看看下面的解释。
如编号为1的那个特征，就是广告实时的ctr，假设互联网广告的点击率符合一个长尾分布，叫做对数正态分布，其概率密度是下图（注意这个是假设，不代表真实的数据，从真实的数据观察是符合这么样的一个形状的，好像还有雅虎的平滑的那个论文说它符合beta分布）。
![][13] 
对于不同档次的点击率来说，重要程度是不一样的，比如在接近对数正态分布的那个拱附近（0.2%左右）的点击率，由于这类型的情况比较多，重要程度并不高，特征的权重需要小一点；但是对于接近那个长尾的那些点击率来说，这种情况比较少，重要程度高，特征的权重也应该大一点。下面是重要程度分布图。
![][14]
如果直接用ctr的那个浮点值作为特征，训练后，对这个特征，只有一个权重，没办法把重要程度区分开来，所以效果不好。
当然，点击率与重要程度不一定是完全的正相关性，有可能值越大特征越重要，也有可能值增长到了一定程度，重要性就下降了。这样的就是非线性的情况，利用一个线性的方式去拟合，效果自然打折扣。
解决的方法就是把ctr那个浮点值离散化。
百度有科学家提出了对连续特征进行离散化。他们认为，特征的连续值在不同的区间的重要性是不一样的，所以希望连续特征在不同的区间有不同的权重，实现的方法就是对特征进行划分区间，每个区间为一个新的特征。
具体实现是使用等频离散化方式：1）对于上面的编号为1的那个特征，先统计历史记录中每条展示记录中编号为1的特征的值的排序，假设有10000条展示记录，每个展示记录的这个特征值是一个不相同的浮点数，对所有的展示记录按照这个浮点数从低到高排序，取最低的1000个展示记录的特征值作为一个区间，排名1001到2000的展示记录的特征值作为一个区间，以此类推，总共划分了10个区间。2）对特征编号重新编排，对于排名从1到1000的1000个展示记录，他们的原来编号为1的特征转变为新的特征编号1，值为1；对于排名是从1001到2000的记录，他们的原来编号为1的特征转变为新的特征编号2，值为1，以此类推，新的特征编号就有了1到10总共10个。对于每个展示记录来说，如果是排名1到1000的，新的特征编号就只有编号1的值为1，2到10的为0，其他的展示记录类似，这样，广告本身的ctr就占用了10个特征编号，就成为离散化成了10个特征。
另外的两个交叉ctr也是用这样的方式离散化成了10个特征，那样总共就有了30个特征。训练的结果w就会是一个30维的向量，分别对应着30个特征的权重。
实际的应用表明，离散化的特征能拟合数据中的非线性关系，取得比原有的连续特征更好的效果，而且在线上应用时，无需做乘法运算，也加快了计算ctr的速度。

* 1.4 离线指标评估
 特征想到了，分析完了，加工过了，就需要出些跟线上应用相关的东西流量，就是离线指标。
离线指标可以先评估单特征AUC，就是根据这个特征的取值情况，就是前面离散化之前的那个浮点值，跟真实的点击数据组合成一对数据，去计算AUC，如果AUC大于0.6，就已经算是一个很不错的特征了；如果很接近0.5，说明识别能力不强，还要继续加工或者放弃。
为了跟线上情况一致，要做的事情就是跟线上目前情况一样，先训练一个模型，再把测试样本经过模型，得到一堆预估的ctr，再根据这些ctr很真实点击情况对比，计算一些指标。
评估模型效果的方法有很多，主要有以下两个：
  1. AUC，从排序的角度评估模型预估效果；
  2. MAE（Mean Absolute Error）/MSE（Mean Squared Error），从准确率的角度评估模型预估效果；
  AUC在其他的博文里面详细描述了，主要比较正负样本的序关系。
  MAE就是看预估的ctr与真实的ctr的差的情况，估得越准确越小，MSE同理。

* 1.4 线上效果评估
离线评估完后，只是对这个特征有了个期待，但是决定特征能否上线的还是在线的A/B Test，即随机选取两部分线上同质流量，一部分用基准模型A进行实际投放，一部分用加了新特征的模型B进行投放。如果后者对在线业务指标（如点击率、千次展现收益等）有正向效果，就认为是好模型，特征就是好特征，这个特征就可以上线了。

* 1.5特征上线
在A/B Test过程中，的如果模型B业务指标一直比模型A好，模型B就可以全量上线了，这样，新特征也全量上线了。到这，一个特征的上线过程就描述完了
新的业务策略上线同样也是用这种方法。

* 1.6 特征生成
 在前面说特征生成的时候，还是挺靠前的，但是为了描述的流畅性，就放到了最后。
前面一直在说想特征，分析，加工啥的，就是没有说一个事情，特征怎么从离线数据中获取。其实不是这个工作不重要，而是这个工作又杂又繁琐。
  * 一、先说实时广告ctr吧，其实这个是整整一个项目的结果。
   步骤如下：
   1. 广告投放平台投放广告，结算系统产生投放日志和点击日志。
   2. 日志发送到收集系统。
   3. 实时计算程序实时读取日志，解析，获取其中的广告信息。
   4. 按照时间窗口进行统计pv，click。
   5. 写入线上存储器提供读取。
   6. 线上实时进行加工。
  * 二、再说交叉特征
 对于性别/广告主交叉特征。
这个也要根据实时的投放日志，根据用户id，从日志/数据仓库获取用户性别，再统计每个广告主在每个性别上的点击率，可以经过一些加工，写入线上存储器供线上程序读取。
上面两点，看起来简简单单几句话，却跨域了4个部门，需要各种的沟通合作，才能得到线上的数据。广告投放平台与结算系统，日志收集与实时计算，线上存储器，分别是由三个部门提供的服务。完成这些工作需要大量的沟通工作。
数据生成后验证正确性是很耗时间的，因为只能在某个时间点读出来，再根据日志里面时间戳去统计，两个对比，看看数据是否正确。
验证工作耗费比较大的精力，还要比较多的精力去调试，保证整个项目各个模块的稳定。还要根据其他一些数据建立数据监控。
特征工程还会遭遇其他方面的问题，如某个系统出问题，如结算系统，发送日志错误了，重复发送了，就会导致数据监控方面的报警。还容易遇到的问题是，线上存储器空间不足，导致有些特征导入失败，线上使用也出了问题等等。一时半会是说不完的，工程上的问题也会困扰算法的优化工作。
用linkin的ppt上的一页来说吧。
![][15]
大致情况就是这样了。
一旦搭上特征工程这个贼船，就没得脱身的了。
没见到哪个书好好描述一下这个情况：数据不光变化，还是不稳定的变化，随时出现的脏数据让人猝不及防。
模型不断在更新，但是要选择一个好的模型，也是非常难的，有时候得人工介入。上面那页PPT真是“满纸荒唐言，一把辛酸泪”。不是身在其中，又如何体会费老大的劲搞出来的一个特征，在线上怎么都没有产生预期的效果，各种扒拉日志与分析；一个月也看不到什么像样的指标提升的尴尬事更是屡见不鲜。

#####八  机器学习与数据
写好标题，却迟迟不知道怎么动手，最近机器学习的一个分支——深度学习，真是火得没朋友啊，过去十几年的最热门的核方法，被成功的放到一边去了，整个工业界开始重新聚焦到神经网络这边来了。
方法万能论总是那么让人热血沸腾的。
可惜经过一段时间的摸爬滚打，脑子总算清醒了一点，也从一个广告算法工程师的角度去看看这个问题吧。
也不谦虚了，就打个比方吧，把角色分一下好说话。类别互联网广告（或者说数据挖掘领域），拿餐馆做比喻的话，那么数据就是食材，算法工程师就是厨师，算法就是配料。一道菜要好吃，就得要求食材好，厨师好，配料好而且用得好。
所以一道菜好不好吃，不是在一个点完全决定的，而是综合的作用的。
下面就分别论述一下吧。  

* 1.1 数据是王道
 上面说过了，数据是食材，食材的质量本质上决定的一道菜能做到多好。食材不好，配再好的厨师，用再好的配料，都是烂泥扶不上墙的。
那么就要求有很好的数据了，那么问题就来了——什么样的数据才是好的数据？
这个问题就及其难以回答了，如果从互联网广告方面看，还算有经验。下面就班门弄斧自问自答了。
用户的profile，如年龄，性别，职业，地域（细化到某区会更好），教育水平，婚恋状态，登陆的平台（手机型号或者PC），社交好友圈，关注的名人，平时浏览的网页，平时泡的论坛，经常使用的应用等等。
为啥呢？
因为广告主都是卖东西的，一个人的年龄，性别，职业等等因素，很大程度上影响了这个人的兴趣点所在。而婚恋状态，很好说明的这个人在某些东西上面的需求；登陆的平台，一定程度上反应了一个人的消费水平甚至消费观念；职业，能说明一个人的财富水准；社交好友圈，也能反映一个人的财富水准以及兴趣圈子；关注的名人，平时浏览的网页，平时泡的论坛，经常使用的应用等，都能准确反应一个人的兴趣，不同的名人，网页，论坛，应用，可以认为是不同的兴趣的体现。
用户对广告的历史点击行为序列，也可以认为是比较有效的数据，只是会是一个瞬时发送的兴趣，瞬间消失，那是需要实时捕捉的，大部分广告平台都能得到这样的数据。
有些广告平台就没有这么好的数据了，一个人的profile数据就是非常难以获取的，相当多的DSP，其实连识别一个人都有难度，更别提用户的profile了。
如果没有profile，就依赖很多方法去估算或者去一些平台去爬，当然也可以去向DMP请求。
由这里，其实就诞生了很多工作——数据收集，清洗。这个也可以比喻成采购食材。在这一步，就可以使用一些数据挖掘的算法了，比如在清洗阶段，有些统计知识如均值，方差，数据挖掘方法如异常点检测，都能用上了。如先把数据拟合一下正态分布，把离分布中心很远的样本舍弃掉。
有些不知道年龄的用户，就用一些分类方法或者聚类去估计，这是就有决策树或者svm，kmeans的上场的机会了。
用户的职业的估计方法也很复杂，一些基本的入手思路就是从好友圈传递过来，比如好友圈里面大部分都是程序员，这个人也认为是程序员。
关注的名人、浏览的网页、使用的应用、泡的论坛，这几个都有兴趣倾向的。就需要使用LDA等等建模方法，把一个名人，网页，应用，论坛变成一个个兴趣的向量，再根据一个人在各个来源方面的倾向，给一个人分配一个兴趣向量。然后就可以根据兴趣来进行商业上面的对广告主的匹配程度了，如一个人经常关注科比，逛篮球论坛，看篮球新闻，那么这个人对篮球的相关广告也会有比较大的好感。这里，topic model啊，分词方法啊，甚至分类、回归方法都能用上；如果炫一点，还能用上深度学习算法。
有了这些用户的profile，才能把特征工程做起来，不然特征工程就巧妇难为无米之炊了。看前面的博文，各种交叉组合特征，都是建立在这个profile已经建立的情况下的，如果没有这些profile，特征工程就黄了。
对于挖掘用户profile的工程师来说，食材就是那些从各个地方收集过来的数据，他们自己是厨师（往往也是那个洗菜的），利用各种工艺和配料生成了数据。他们的产出，一部分直接端给客人了（广告主做定向），一部分作为二级食材，让大师傅（竞价排序的负责人）再加工，加配料，做出了一道大菜（广告业务），也端出去给大客人了（老板与董事会）。

* 1.2 选择合适的算法
 所谓算法是配料，就是对相同的食材，用不同的配料，得到的菜味道是不一样的。就像荔枝蘸盐蘸醋吃，味道是不一样的。
如ctr预估模型，有logisticregression，也有gbdt，也有阿里盖坤的分片线性模型，甚至有random forest，这几种预估方法，在相同的数据上面，会出现不一样的效果，有些估得会更准，有些估得不准。
又如估年龄的方法，可以利用用户的各种行为，各种关注的名人、浏览的网页、使用的应用、泡的论坛作为特征，用svm去估，能得到一个结果；用kmeans来估，又是一个结果；当然也可以根据他好友圈的年龄的平均，或者中位数，也能得到一个结果；根据他的职业和婚恋状态，利用logistic regression来估，也有一个结果。这各种结果基本都不一样，有些准，有些不准。
又如挖掘用户兴趣，利用topicmodel先把一个名人，网页，应用，论坛变成一个个兴趣的向量，再根据一个人在各个来源方面的倾向，给一个人分配一个兴趣向量，能得到一个结果；直接根据运营指定一些论坛，或者频道，网页的兴趣，然后再加权分配给每个人，也能得到一个结果；把每个广告主指定兴趣向量，根据用户的历史行为数据，每点击一个广告主，就把这个广告主的兴趣向量分给这个用户，也能得到一个结果；根据用户的各种行为，各种关注的名人、浏览的网页、使用的应用、泡的论坛作为特征，利用kmeans进行聚类，对每个类别，用相似计算的方法，或者人工指定一个兴趣向量，也能得到一个结果；把用户所有的数据一起拿过来，利用word2vec和一些深度学习的方法，得到一个用户的表征的向量，也得到了每个广告主，或者兴趣类目的表征的向量，相关的向量做相似度计算，也能得到用户兴趣向量。
综上，算法可以各种挑着用（配料嘛），出来的结果不一样，有些好，有些不好。这就很依赖人工或者线上效果去验证，评估哪个好了，好的结果才拿出去见客人，差的就不能用了。
到这，不知道大家明白了没有，说这么多，也没有说哪个算法好，而是要根据食材不同，去优选最合适的。这个跟找配偶一样的，没有最好的，只有最合适的。

* 1.3 算法工程师的工艺
  所谓看工艺，就看算法工程师的理论功底和经验了。
每个配料生产厂家都会大肆宣扬他们家的配料好，算法工程师不能每家都相信，但也不能每家都不相信，只好都试试看，选择最适合自家食材的就行。
算法工程师同样也是，选择最合适的算法来完成任务就可以了。
同样的数据，同样的可供选择的算法，在不同的算法工程师手里，依然会出现不一样的结果，如当年某公司做ctr预估的时候用的很多是连续型特征，后来某大牛过来负责后，替换成了离散型的特征，效果就好了。对于各个公司来说，找到不同的算法工程师，也能决定一个业务的能做成什么样子。
对于算法工程师来说，确实没有一劳永逸的方法，成长也没有什么捷径，摸爬滚打地成长似乎免不了，有些聪明的人，可能会快一点。以下算是一些成长经验吧。
首先算法工程师也要成长为产品经理，要加强业务功底，根据业务需求决定优化的一个限度。要注意的是，比如预估年龄这样的一个任务，可以有很多种做法，各种做法难度不一样，投入产出比不一样，投入人力也不一样，算法工程师需要了解业务对这个年龄的需要程度（是否绝对的决定收入？），还需要了解当前团队的实力以及资源（机器，可用工具），再选择一两个合适的算法去试，同时还要决定，当哪些条件满足的时候，任务就可以告一段落了。
上面对“算法工程师需要”后面的那些话，说起来好像非常清楚，只是，真有这种感觉的人才是站着说话不腰疼。
这个“了解业务对年龄的需要程度”，也是一个不容易的任务，产品经理需要的肯定是越准确越好，运营也是这么觉得的，觉得错一两个都不行，但是能做到吗？那么能做到多少是正确的？90%？80%？70%？年龄在整个业务里面占什么样的地位？定向那里算一个，ctr预估那里算一个，还有算法的其他一些挖掘算一个，整个业务的全景都了解了，才能具备“了解业务对年龄的需要程度”这个条件。
“了解当前团队的实力以及资源”，这话也是知易行难啊，了解团队的实力这个事情靠跟同事合作得来的，还得了解自己有几斤几两，这个往往有人不容易做到了；另外团队有多少机器和工具都清楚，但是这些机器也不是全部用来弄年龄这个事情的，还有其他任务要做的；团队里谁来做这个任务，或者自己做需要多少时间，其他任务怎么安排，都是问题的。老板不会专门找个挖掘年龄的人来放着的。
而“选择一两个合适的算法去试”这句话倒不简单，首先算法工程师得了解多个算法的优缺点，还得了解它们的实现难度，还需要知道当前团队有了什么样的工具可以加快速度，然后再选的算法。而了解多个算法的优缺点，还真是一件巨无霸的难事，人的精力有限，可能一直在了解着各种算法呢，要好好了解一个算法都是很需要精力的，必要的时候还得做写实验才能了解；这事也没有很好的捷径，好好加强数学功底，学会解释模型，积累对各种算法的使用经验，慢慢成长，才有能更好地选择算法。
工作后，公司不是学校，业务是最好的推动力。作业可以抄，工作却不是那么容易抄的，各个公司具有的条件不一样，很难抄得来。有的算法工程师开始工作的时候，有一个经验丰富的大哥带着，手办眼见，在打下手的同时积累了相当的经验，成长成为一个合格的算法工程师，这个途径算是比较顺利的；有时候情况是，一开始大家都不懂，一起摸爬滚打，在经过各种挫折和打击之后，慢慢成长成为一个优秀的算法工程师，这是另一种途径。无论走哪个途径，都没有一步登天的路，加强理论功底，积累实战经验，是最有成效的方式了。

* 1.4 后话
  曾经也是热血青年，也曾为某个算法牛不牛逼纠结很久，读研的时候还觉得对某个算法做了一点点事情就多牛逼了。没想过工作后被现实狠狠打脸了。工作的前面很长的时间内，其实都是一个收菜、验菜、洗菜的小伙计，偶尔还要修水龙头，修洗菜池，好久才能自己挽起袖子去加工一下食材，做成二级食材供大师傅使用，也经常遇到满心希望能做好的菜做砸了。
如果上面的话不清楚，就用术语来说，就是工作后一段时间内，都在看数据排查数据，清洗处理数据，说好听点的就是评估特征。然后还经常导数据，还包括搭建一些基础服务，如线上存储器，实时流系统等。后面有了经验后，才慢慢自己去想一些特征，去生成特征，评估，加入模型上线等等一套流程走完。
在这段时间里面，看了一些paper，也了解了其他同行怎么做的，也开始用新的视角去看待各个算法，也开始有了对一些算法的实战经验，了解了一些工具，会使用一些工具。对业务也越来越熟悉了，才有了一些算法工程师的样子。
目前的状态还是——衣带渐宽终不悔，为伊消得人憔悴吧。
没觉得轻松，但是也不知道说什么苦好。
“沉舟侧畔千帆过，病树前头万木春”，互联网时代一切都在发展，需要努力跟上。这几篇博文都是经验之谈，希望能帮助一些人吧。

#####九、 互联网广告系统 之 word2VEC

* 一、 对广告主的辅助
  * 1.1基本概念
  互联网广告的广告主其实往往有他们的困惑，他们不知道自己的目标人群在哪里。所谓目标人群，就是广告主想向他们投广告的那帮人。就像互联网广告的一个大牛的一句名言——我知道互联网广告有一半是浪费的，问题是我不知道是哪一半。
这个困惑就给媒体带来一个义务——要帮助广告主定向他们的目标人群。
对于普通的广告主来说，比如说一个化妆品广告的广告主，它的目标人群很明显就是年轻的女性。注意关键词“年轻”和“女性”，这是决定媒体这边能否赚到钱的关键词。要知道对于媒体来说，广告主是它们的客户，满足客户的要求，客户就给它们钱，不满足客户的要求，就没有人为媒体买单；没有人为媒体买单，媒体就没有钱养它们的员工和机器，也弄不来新闻和互联网的其他内容，那样媒体公司就垮了……
那么在媒体这边，需要做的的工作就很明确了——满足它们的客户（也就是广告主）的需求。怎么满足呢？这工作说容易也容易，说简单也简单，就是把喜欢这个广告主的广告的人找出来，然后帮这个广告主把他们的广告投放给这些人，让这些人看到这个广告主的广告。
这个工作带来的问题就真多了，媒体又不是什么神人，比如说一个新闻网站，浏览这个网站的每天有100万人，这个新闻网站的员工不可能一个个去访问他们的用户（浏览这个网站的人），整天问他们你喜不喜欢化妆品啊，喜不喜欢体育啊之类的问题。
那怎么办呢？媒体的员工只好猜了，但是哪怕是猜都很费劲，想想都头疼，一百万人啊，一个个猜也得吃力不讨好啊。这时候计算机的作用就来了，用计算机猜嘛，而且不一定需要全部瞎猜的，因为用户如果注册了的话，还有一些用户的个人信息可以参考的。一般的网站注册的时候都要求提供年龄性别之类的个人信息，有时候要要求写一些个人的兴趣什么的标签。这个时候这些数据就用上大用处了。
网站可以把注册用户的个人信息保存下来，然后提供广告主选择。如上面的那个化妆品的广告主，它就可以跟媒体提它的要求——我要向年轻的女性投放广告。媒体这个时候就可以提供一些条件给这个广告主选择，如媒体说我有很多用户，18到80岁的都有，然后男性女性用户都有。广告主就可以根据这些条件选择自己的目标用户，如选择了18到30岁的女性用户作为目标人群。选中了目标人群后，广告主和媒体就可以谈价钱了，谈好了价钱广告主就下单，然后媒体就帮广告主投广告，然后媒体的钱就赚到了。

 * 1.2兴趣挖掘的必要性
 上面多次提到的“目标人群”，就是广告主最关心的事情。客户最关心的事情自然也是媒体最关心的事情。所以媒体会尽力帮助它们的客户去定向它们的目标人群。
一般所谓的定向也不是媒体亲自有一个人来跟广告主谈的，是媒体建立好一个页面，这个页面上有一些选项，比如年龄，性别，地域什么的，都是条件。广告主在上面把自己的目标人群符合的条件输入，然后下单购买向这些人投放广告的机会。
媒体为了更好地赚钱，肯定是愿意把这个页面上的条件做得更加丰富一点，让更多的广告主觉得这个网站的用户里面有它们的目标人群，从而让更多的广告主愿意过来下单。
广告主的定向其实有粗细之分的，有些广告主粗放点，它们有钱，选的定向条件比较宽，就说女性的用户，全部都投放；有些就定向得比较窄，比如说，北京的20到25岁的女性，并且要喜欢羽毛球的用户。对于定向宽的广告主好处理，问题就是这些定向窄的广告主，它们还希望知道用户的兴趣所在，这就麻烦了。
为啥麻烦呢？一个用户的兴趣鬼才知道呢。就算当面问，人家也不乐意回答，何况就凭借一点点东西瞎猜。但是为了赚钱，瞎猜也得上的了，工业界为了赚这个钱，诞生了整整一个行业——数据挖掘，甚至在学术界还有一个更加生猛的名字——机器学习。学术界的那个名字和解释都是相当大气的：让机器学会像人一样思考。工业界就务实一点，只是对数据内容本身做一个挖掘，获取到啥呢？一般就是用户的兴趣啊，爱好啊什么的。这些东西供谁使用呢？暂时看来只有广告主愿意为这些掏钱，其他的就有些媒体做来让自己推荐的内容不至于让用户那么反感而已。
上面有个名词“数据”，没错了，这个词是互联网广告业，甚至是数据挖掘行业的核心的东西。所谓数据，这里简单点说就可以认为是用户的年龄、性别、地域等用户的基本属性；复杂点说可以说是用户兴趣、爱好，浏览记录等；更高级的有用户的交易数据（当然这个高级的数据很少媒体能搞得到）等。
解释完“数据”这个词，结合一下广告这个场景，就可以得到活在媒体公司里面的互联网广告行业数据挖掘工程师的工作是什么了。他们的工作就是：根据用户自身的基本属性和用户流量的网页记录以及内容，想方设法让计算机猜出用户的兴趣爱好。用户的兴趣爱好“挖掘”出来后，就可以作为定向条件放到上面说的那个网页上面供广告主选择了。这事情整好了，广告投了有人点击，公司的钱就赚到了；没整好，广告没人点击，广告主不乐意下单了，公司就赚不到钱……怎么着？炒这些工程师的鱿鱼去。
上面可以看到了，辅助广告主定位它们的目标人群是很重要的。
经过一番的探索，word2vec在互联网广告上面也是可以辅助广告主定向他们的目标人群的，下面就讲讲这个算法在互联网广告的应用吧。

* 1.3 利用word2ec给广告主推荐用户
 为了用上word2vec，把场景转换到一个新闻媒体如A公司。
在A公司的多个页面中，电商公司B有他们的一个主页，专门介绍他们公司一些产品促销，抢购和发布会什么的。
公司A目前有很多用户的浏览数据，如用户u浏览了公司A的页面a1，a2，a3等。
把这些数据处理一下，整合成word2vec能处理的数据，如下
U1  a1,a2,a3……
U2  a2,a3,a5,……
U3  a1,a3,a6,……
其中u1，u2，u3表示不同的用户，后面的一串表示这些用户的浏览记录，如U1  a1,a2,a3表示用户u1先浏览了页面a1，再浏览a2，然后浏览了a3,……
这些数据还不符合word2vec的输入数据格式，把第一列去掉，变成下面的样子
a1,a2,a3……
a2,a3,a5,……
a1,a3,a6,……
这些数据就可以作为word2vec的输入数据了。
就把这些数据作为word2vec的训练数据，词向量维度为3，进行训练，完成后得到下面的输出
A1  (0.3,-0.5,0.1)
A2  (0.1,0.4,0.2)
A3  (-0.3,0.7,0.8)
……
An  (0.7,-0.1,0.3)
就得到了每个页面的向量。
这些向量有啥意义呢？其实单个向量的意义不大，只是用这些向量可以计算一个东西——距离，这个距离是页面之间的距离，如页面a1和a2可以用欧式距离或者cos距离计算公式来计算一个距离，这个距离是有意义的，表示的是两个网页在用户浏览的过程中的相似程度（也可以认为是这两个页面的距离越近，被同一个人浏览的概率越大）。注意这个距离的绝对值本身也是没有意义的，但是这个距离的相对大小是有意义的，意思就是说，假设页面a1跟a2、a3、a4的距离分别是0.3、0.4、0.5，这0.3、0.4、0.5没啥意义，但是相对来说，页面a2与a1的相似程度就要比a3和a4要大。
那么这里就有玄机了，如果页面a1是电商公司B的主页，页面a2、a3、a4与a1的距离在所有页面里面是最小的，其他都比这三个距离要大，那么就可以认为同一个用户u浏览a1的同时，浏览a2、a3、a4的概率也比较大，那么反过来，一个用户经常浏览a2、a3、a4，那么浏览a1的概率是不是也比较大呢？从实验看来可以这么认为的。同时还可以得到一个推论，就是用户可能会喜欢a1这个页面对应的广告主的广告。
这个在实验中实际上也出现过的。这里模拟一个例子吧，如a1是匹克体育用品公司在媒体公司A上的官网，a2是湖人队比赛数据页，a3是热火队的灌水讨论区，a4是小牛队的球员讨论区。这个结果看起来是相当激动人心的。
根据这样的一个结果，就可以在广告主下单的那个页面上增加一个条件——经常浏览的相似页面推荐，功能就是——在广告主过来选条件的时候，可以选择那些经常浏览跟自己主页相似的页面的用户。举个例子就是，当匹克体育用品公司来下单的时候，页面上给它推荐了几个经常浏览页面的粉丝：湖人队比赛数据页，热火队的灌水讨论区，小牛队的球员讨论区。意思是说，目标人群中包括了经常浏览这三个页面的人。
这个功能上线后是获得过很多广告主的好评的。
这样word2vec这个算法在这里就有了第一种用途。


* 二、 对crt预估模型的帮助
 根据另一篇博文《互联网广告综述之点击率系统》，里面需要计算的用户对某广告的ctr。在实际操作的时候，这个事情也是困难重重的，其中有一个冷启动问题很难解决。冷启动问题就是一个广告是新上线的，之前没有任何的历史投放数据，这样的广告由于数据不足，点击率模型经常不怎么凑效。
但是这个问题可以使用同类型广告点击率来缓解，意思就是拿一个同行的广告的各种特征作为这个广告的特征，对这个新广告的点击率进行预估。
同行往往太粗糙，那么怎么办呢？可以就利用跟这个广告主比较相似的广告的点击率来预估一下这个广告的点击率。
上面说过，可以得到每个页面的词向量。这里的方法比较简单，如在媒体公司A上面有1000个广告主，它们的主页分别是a1、a2、……、a1000。
根据上面的方法，得到了这1000个词向量，然后运行kmean或者其他聚类算法，把这1000个广告主聚成100个簇，然后每个簇里面的广告主看成是一个。
这里可以模拟一个例子，聚类完成后，某个簇c里面包含了几个广告主的主页，分别是京东商城，天猫，唯品会，当当，聚美优品，1号店，蘑菇街，卓越，亚马逊，淘宝这10个，这10个的目标人群看起来基本是一致的。
这里的看成是一个簇是有意义的，比如说第一个簇c1，c1这个簇里面的所有历史投放数据和实时数据可以做特征，来预估这个流量对这个簇的ctr。得到这个ctr后，就很有用了，如果某广告投放数据比较充分，就直接预估这个广告的ctr；如果某广告的历史投放数据很少，就用这个广告主所在的簇的ctr来代替这个广告，认为对簇的ctr就是这个广告的ctr，这样能让一个新广告也能得到相对靠谱的预估ctr，保证不至于乱投一番。

* 三、 一些总结
 如何应用好一个算法，确实是很多算法工程师的一个重大课题。
数据挖掘算法工程师经常要面对的一个难题就是：这个算法怎么用到我们的数据上面来？有不少同学会认为是：我到了公司，就发明一个很牛逼的算法，把公司的原来的问题解决掉，然后大大增加了效果，获得了领导的好评。这个天真烂漫的想法就不评价了，免得被说打击人。互联网企业里面的真实情况是算法工程师面对那一团乱遭的数据，得想尽办法去把数据整合成能用的格式。
拿上面的（1.3）中的例子，那个把数据组合成a1,a2,a3……这样一行行的，然后进入word2vec去进行训练是最难想到的而且是最核心的东西，虽然明着说是word2vec这个算法厉害，实际上面是“把数据整合成合适的方式交给word2vec进行训练”这个想法重要，因为尝试了很多想法，做了很多实验才能想到这样的一招的。
还有数据的整合其实也费了很多功夫的，比如说媒体有些用户是一些机器的账号，人家乱搞的，要想办法排除掉的，而“想办法排除”这么简单一句话，真正要做的工作真是多多的有。
哪怕结果都训练出来了，怎么解释这个结果是好的？这个问题也是得想了一段时间的，后来是实验发现了利用词向量的距离来评价相似性这个东西最靠谱，然后才用上的。
一个数据挖掘的过程其实不简单，这个博客也没办法一一体现做的过程里面的那些各种折腾，各种不顺畅。
数据挖掘工程师经常要面对的另一个难题就是：明明理论上推得杠杠的，算法性能也是杠杠的，但是对于互联网广告的效果，怎么就那么不咸不淡的呢？
这个问题真没有什么统一的答案，这种现象多了去了。经常遇到的原因有：数据本身处理的方式不对和算法不合适。
所谓数据本身处理的方式，可以参看博文《互联网广告综述之点击率特征工程》，里面说的那些方法不是从哪本书上面看到的，是经过比较长时间实践，然后各种折腾，各种特征取舍，各种胡思乱想，各种坑踩出来的。可能志在学术的人看起来都简单，实际上课本那些东西，学生们吹起牛皮来不眨眼的那些东西，一跟真实应用场景结合起来就各种坑要踩的了。
拿上面的（二）中的例子来看。方法简单得不得了，但是可以想象一下，word2vec牛逼啊，kmeans牛逼啊，第一次聚类出来的结果也不过如此。后来又加入了每个广告主的行业和地域作为特征，而且这个加特征，就是直接把行业和地域处理一下，连接到广告主的词向量后面的。如a1的词向量是(0.3,-0.5,0.1)，然后假设只有两个行业，体育和化妆品，处理成二值特征，占据第4和5两个index，第4个特征为1，第5个特征为0表示体育类广告主，反过来，第4个特征为0，第5个特征为1表示化妆品；再对地域的下标做了一下处理，成为二值特征，比如说占据了6到10这5个位置（假设第6个位置为1，其余7到10为0表示北京；第7个位置为1，其余为0表示广东，以此类推）。
经过了上面的处理，再用kmeans进行聚类，从聚类后一个个簇去看，结果看起来才顺眼了很多。上面的行业和地域特征的加入，也是用了比较多的经验的，不是凭空乱整出来的一个吹牛皮的东西，当然谁有更好的方法，也可以提出来试试看。另外还希望大家注意关键字“一个个簇去看”，这个工作真是费时费力，比较辛苦的。
以上举了一些例子，也把互联网广告的数据挖掘算法工程师的一些工作中的成功和不成功的地方都说出来了，基本上算是实话实说，希望对大家有点帮助吧。有过类似经历的人能看懂，没啥兴趣的就呵呵吧。
[1]:http://img.blog.csdn.net/20141108224113906
[2]:http://img.blog.csdn.net/20141108232715807
[3]:http://img.blog.csdn.net/20141108232819453
[4]:http://img.blog.csdn.net/20141108233354687
[5]:http://img.blog.csdn.net/20141108234114246
[6]:http://img.blog.csdn.net/20141108234133684
[7]:http://img.blog.csdn.net/20141108234504721
[8]:http://img.blog.csdn.net/20141108234148161
[9]:http://img.blog.csdn.net/20141108234158269
[10]:http://img.blog.csdn.net/20141108234203823
[11]:http://img.blog.csdn.net/20140211211940703
[12]:http://img.blog.csdn.net/20140211211947671
[13]:http://img.blog.csdn.net/20140211213441937
[14]:http://img.blog.csdn.net/20141108235704890
[15]:http://img.blog.csdn.net/20141108235712296